{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b84af-8c77-4f60-90ca-fcadcd4d2176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: unsloth 2025.10.8\n",
      "Uninstalling unsloth-2025.10.8:\n",
      "  Successfully uninstalled unsloth-2025.10.8\n",
      "Found existing installation: unsloth_zoo 2025.10.9\n",
      "Uninstalling unsloth_zoo-2025.10.9:\n",
      "  Successfully uninstalled unsloth_zoo-2025.10.9\n",
      "Found existing installation: trl 0.16.1\n",
      "Uninstalling trl-0.16.1:\n",
      "  Successfully uninstalled trl-0.16.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting trl<0.17,>=0.14\n",
      "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.10.12-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting unsloth_zoo\n",
      "  Downloading unsloth_zoo-2025.10.13-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting accelerate>=0.34.0 (from trl<0.17,>=0.14)\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets>=3.0.0 (from trl<0.17,>=0.14)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rich (from trl<0.17,>=0.14)\n",
      "  Downloading rich-14.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting transformers>=4.46.0 (from trl<0.17,>=0.14)\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting wheel>=0.42.0 (from unsloth)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting packaging (from unsloth)\n",
      "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Collecting numpy (from unsloth)\n",
      "  Downloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting tqdm (from unsloth)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting psutil (from unsloth)\n",
      "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.35-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting protobuf (from unsloth)\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 (from unsloth)\n",
      "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.5.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
      "  Downloading peft-0.17.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-1.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.35.2-py3-none-any.whl.metadata (20 kB)\n",
      "INFO: pip is looking at multiple versions of unsloth to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.10.11-py3-none-any.whl.metadata (61 kB)\n",
      "  Downloading unsloth-2025.10.10-py3-none-any.whl.metadata (61 kB)\n",
      "Collecting transformers>=4.46.0 (from trl<0.17,>=0.14)\n",
      "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.10.9-py3-none-any.whl.metadata (59 kB)\n",
      "  Downloading unsloth-2025.10.8-py3-none-any.whl.metadata (59 kB)\n",
      "Collecting filelock (from transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pyyaml>=5.1 (from transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading regex-2025.10.23-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo)\n",
      "  Downloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of unsloth-zoo to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unsloth_zoo\n",
      "  Downloading unsloth_zoo-2025.10.12-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading unsloth_zoo-2025.10.11-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading unsloth_zoo-2025.10.10-py3-none-any.whl.metadata (31 kB)\n",
      "  Downloading unsloth_zoo-2025.10.9-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting pillow (from unsloth_zoo)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting msgspec (from unsloth_zoo)\n",
      "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting setuptools (from torch>=2.4.0->unsloth)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.4.0->unsloth)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.4.0->unsloth)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.3.20 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvshmem_cu12-3.3.20-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting httpx<1.0.0 (from datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting xxhash (from datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub>=0.34.0->unsloth)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting certifi (from httpx<1.0.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1.0.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers>=4.46.0->trl<0.17,>=0.14)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.4.0->unsloth)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1.0.0->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting importlib_metadata (from diffusers->unsloth)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib_metadata->diffusers->unsloth)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.4.0->unsloth)\n",
      "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl<0.17,>=0.14)\n",
      "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->trl<0.17,>=0.14)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich->trl<0.17,>=0.14)\n",
      "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->trl<0.17,>=0.14)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Downloading trl-0.16.1-py3-none-any.whl (336 kB)\n",
      "Downloading unsloth-2025.10.8-py3-none-any.whl (347 kB)\n",
      "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m176.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m472.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m138.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2025.10.9-py3-none-any.whl (269 kB)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m147.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m186.9 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m159.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m200.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m475.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m182.7 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m154.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m237.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m152.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m169.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m146.8 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m150.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m334.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m101.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Downloading peft-0.17.1-py3-none-any.whl (504 kB)\n",
      "Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m142.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m126.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.10.23-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.4/803.4 kB\u001b[0m \u001b[31m313.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m328.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m185.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m310.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchao-0.14.1-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m137.3 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m153.5 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m139.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m217.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.11.0-py3-none-any.whl (109 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading diffusers-0.35.2-py3-none-any.whl (4.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m254.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m261.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
      "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "Downloading pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m163.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m239.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
      "Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m278.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m169.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.35-py3-none-any.whl (132 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Downloading xxhash-3.6.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: torchao, pytz, nvidia-cusparselt-cu12, mpmath, zipp, xxhash, wheel, urllib3, tzdata, typing-extensions, tqdm, sympy, sniffio, six, shtab, setuptools, sentencepiece, safetensors, regex, pyyaml, pygments, pyarrow, psutil, protobuf, propcache, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, multidict, msgspec, mdurl, MarkupSafe, idna, hf-xet, hf_transfer, h11, fsspec, frozenlist, filelock, docstring-parser, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, typeguard, triton, requests, python-dateutil, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, multiprocess, markdown-it-py, jinja2, importlib_metadata, httpcore, anyio, aiosignal, rich, pandas, nvidia-cusolver-cu12, huggingface_hub, httpx, aiohttp, tyro, torch, tokenizers, diffusers, xformers, transformers, torchvision, datasets, cut_cross_entropy, bitsandbytes, accelerate, trl, peft, unsloth_zoo, unsloth\n",
      "\u001b[2K  Attempting uninstall: torchao\n",
      "\u001b[2K    Found existing installation: torchao 0.14.1\n",
      "\u001b[2K    Uninstalling torchao-0.14.1:\n",
      "\u001b[2K      Successfully uninstalled torchao-0.14.1\n",
      "\u001b[2K  Attempting uninstall: pytz━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/91\u001b[0m [torchao]\n",
      "\u001b[2K    Found existing installation: pytz 2025.2\u001b[0m \u001b[32m 0/91\u001b[0m [torchao]\n",
      "\u001b[2K    Uninstalling pytz-2025.2:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/91\u001b[0m [torchao]\n",
      "\u001b[2K      Successfully uninstalled pytz-2025.2━━\u001b[0m \u001b[32m 0/91\u001b[0m [torchao]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu120m \u001b[32m 0/91\u001b[0m [torchao]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.7.10m [torchao]\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.7.1:0m \u001b[32m 0/91\u001b[0m [torchao]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\u001b[0m [torchao]\n",
      "\u001b[2K  Attempting uninstall: mpmath━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/91\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: mpmath 1.3.0━━━━━━━━\u001b[0m \u001b[32m 2/91\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling mpmath-1.3.0:━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/91\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled mpmath-1.3.0━━━━━━━━━━\u001b[0m \u001b[32m 2/91\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: zipp━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]12]\n",
      "\u001b[2K    Found existing installation: zipp 3.23.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling zipp-3.23.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled zipp-3.23.0━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: xxhash━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: xxhash 3.6.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling xxhash-3.6.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled xxhash-3.6.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: wheel━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: wheel 0.45.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling wheel-0.45.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled wheel-0.45.1━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: tzdata━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: tzdata 2025.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/91\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling tzdata-2025.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/91\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled tzdata-2025.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/91\u001b[0m [tzdata]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/91\u001b[0m [tzdata]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0━━━━━\u001b[0m \u001b[32m 8/91\u001b[0m [tzdata]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/91\u001b[0m [tzdata]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━━━━━\u001b[0m \u001b[32m 9/91\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/91\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/91\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/91\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/91\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: sympy0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/91\u001b[0m [tqdm]tensions]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/91\u001b[0m [tqdm]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/91\u001b[0m [tqdm]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: sniffio━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: sniffio 1.3.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling sniffio-1.3.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sniffio-1.3.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: six━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: six 1.17.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling six-1.17.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/91\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled six-1.17.0━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: shtab━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: shtab 1.7.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling shtab-1.7.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled shtab-1.7.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/91\u001b[0m [six]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/91\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: sentencepiece━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/91\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: sentencepiece 0.2.1━━━━━━━━━━\u001b[0m \u001b[32m15/91\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling sentencepiece-0.2.1:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/91\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled sentencepiece-0.2.1━━━━━━━━━━━━\u001b[0m \u001b[32m15/91\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: safetensors━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Found existing installation: safetensors 0.6.2━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Uninstalling safetensors-0.6.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K      Successfully uninstalled safetensors-0.6.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K  Attempting uninstall: regexm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Found existing installation: regex 2025.10.23━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Uninstalling regex-2025.10.23:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K      Successfully uninstalled regex-2025.10.23━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K  Attempting uninstall: pyyaml━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Found existing installation: PyYAML 6.0.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Uninstalling PyYAML-6.0.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K      Successfully uninstalled PyYAML-6.0.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K  Attempting uninstall: pygments━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Found existing installation: Pygments 2.19.2━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/91\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Uninstalling Pygments-2.19.2:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/91\u001b[0m [pygments]]\n",
      "\u001b[2K      Successfully uninstalled Pygments-2.19.2━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/91\u001b[0m [pygments]\n",
      "\u001b[2K  Attempting uninstall: pyarrow[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/91\u001b[0m [pygments]\n",
      "\u001b[2K    Found existing installation: pyarrow 22.0.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/91\u001b[0m [pygments]\n",
      "\u001b[2K    Uninstalling pyarrow-22.0.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/91\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-22.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/91\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: psutilm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/91\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: psutil 7.1.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/91\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling psutil-7.1.3:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/91\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.1.3━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/91\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: protobuf[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K    Uninstalling protobuf-6.33.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K  Attempting uninstall: propcache━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K    Found existing installation: propcache 0.4.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K    Uninstalling propcache-0.4.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K      Successfully uninstalled propcache-0.4.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/91\u001b[0m [psutil]\n",
      "\u001b[2K  Attempting uninstall: pillow0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/91\u001b[0m [propcache]\n",
      "\u001b[2K    Found existing installation: pillow 12.0.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/91\u001b[0m [propcache]\n",
      "\u001b[2K    Uninstalling pillow-12.0.0:0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/91\u001b[0m [propcache]\n",
      "\u001b[2K      Successfully uninstalled pillow-12.0.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/91\u001b[0m [propcache]\n",
      "\u001b[2K  Attempting uninstall: packaging[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: packaging 25.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling packaging-25.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.90━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.90:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.90━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.93:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93━━\u001b[0m \u001b[32m25/91\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/91\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.27.3━━━━━━\u001b[0m \u001b[32m28/91\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.27.3:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28/91\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.27.3━━━━━━━━\u001b[0m \u001b[32m28/91\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/91\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.90━\u001b[0m \u001b[32m29/91\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.90:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/91\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.90━━━\u001b[0m \u001b[32m29/91\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.13.1.3━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.13.1.3:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.13.1.3━━━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:━━━━━━━━━━━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93━\u001b[0m \u001b[32m30/91\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/91\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90[0m \u001b[32m33/91\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/91\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90━\u001b[0m \u001b[32m33/91\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/91\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.4.1━━\u001b[0m \u001b[32m34/91\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.4.1:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34/91\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1━━━━\u001b[0m \u001b[32m34/91\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: numpy90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35/91\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: numpy 2.3.4━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/91\u001b[0m [numpy]las-cu12]\n",
      "\u001b[2K    Uninstalling numpy-2.3.4:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/91\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.3.4━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/91\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: networkx╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/91\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: networkx 3.5━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/91\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.5:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.5━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: multidict╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: multidict 6.7.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling multidict-6.7.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled multidict-6.7.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: msgspec[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: msgspec 0.19.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling msgspec-0.19.0:0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled msgspec-0.19.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: mdurl╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: mdurl 0.1.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling mdurl-0.1.2:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled mdurl-0.1.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.3━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.3:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: idnam╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: idna 3.11━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling idna-3.11:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled idna-3.11━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: hf-xet\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: hf-xet 1.2.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling hf-xet-1.2.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled hf-xet-1.2.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37/91\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: hf_transfer╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K    Found existing installation: hf_transfer 0.1.9━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K    Uninstalling hf_transfer-0.1.9:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K      Successfully uninstalled hf_transfer-0.1.9━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K  Attempting uninstall: h11[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K    Found existing installation: h11 0.16.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K    Uninstalling h11-0.16.0:91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K      Successfully uninstalled h11-0.16.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K  Attempting uninstall: fsspecm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.9.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K    Uninstalling fsspec-2025.9.0:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.9.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43/91\u001b[0m [hf-xet]\n",
      "\u001b[2K  Attempting uninstall: frozenlist90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: frozenlist 1.8.0━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling frozenlist-1.8.0:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled frozenlist-1.8.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: filelockm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.20.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.20.0:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.20.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: docstring-parser90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: docstring_parser 0.17.0━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling docstring_parser-0.17.0:0m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled docstring_parser-0.17.0━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.00m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/91\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizerm\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.4━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.4:0m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.4━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: certifi91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: certifi 2025.10.5━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling certifi-2025.10.5:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.10.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: attrs\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: attrs 25.4.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling attrs-25.4.0:[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled attrs-25.4.0m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: aiohappyeyeballs[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: aiohappyeyeballs 2.6.1━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling aiohappyeyeballs-2.6.1:[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled aiohappyeyeballs-2.6.1━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: yarlm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: yarl 1.22.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling yarl-1.22.0:\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled yarl-1.22.00m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: typeguardm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: typeguard 4.4.4━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling typeguard-4.4.4:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled typeguard-4.4.4━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: triton[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: triton 3.4.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/91\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling triton-3.4.0:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled triton-3.4.0\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: requests━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: requests 2.32.5━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling requests-2.32.5:\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.50m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: python-dateutil\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.8.93[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.8.93:━━━━━━━━━━━━━━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93━\u001b[0m \u001b[32m57/91\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu120m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m60/91\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.83━━\u001b[0m \u001b[32m60/91\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.83:[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m60/91\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83━━━━━━━━\u001b[0m \u001b[32m61/91\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu121m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m61/91\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.10.2.21━━\u001b[0m \u001b[32m61/91\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.10.2.21:[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m61/91\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21━━━━\u001b[0m \u001b[32m61/91\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: multiprocess[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.16━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.16:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.16━━━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: markdown-it-py0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: markdown-it-py 4.0.0━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling markdown-it-py-4.0.0:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled markdown-it-py-4.0.0━━━━━━━━━━━\u001b[0m \u001b[32m62/91\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: jinja2━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.6[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K  Attempting uninstall: importlib_metadata\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K    Found existing installation: importlib_metadata 8.7.0━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K    Uninstalling importlib_metadata-8.7.0:\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K      Successfully uninstalled importlib_metadata-8.7.0━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K  Attempting uninstall: httpcore\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K    Found existing installation: httpcore 1.0.9[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K    Uninstalling httpcore-1.0.9:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K      Successfully uninstalled httpcore-1.0.9m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m64/91\u001b[0m [markdown-it-py]\n",
      "\u001b[2K  Attempting uninstall: anyio━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]y]\n",
      "\u001b[2K    Found existing installation: anyio 4.11.00m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K    Uninstalling anyio-4.11.0:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K      Successfully uninstalled anyio-4.11.0\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K  Attempting uninstall: aiosignal\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K    Found existing installation: aiosignal 1.4.0[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K    Uninstalling aiosignal-1.4.0:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K      Successfully uninstalled aiosignal-1.4.0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K  Attempting uninstall: rich━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K    Found existing installation: rich 14.2.0[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K    Uninstalling rich-14.2.0:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K      Successfully uninstalled rich-14.2.0╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m67/91\u001b[0m [httpcore]\n",
      "\u001b[2K  Attempting uninstall: pandas━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m70/91\u001b[0m [rich]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.3[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m70/91\u001b[0m [rich]\n",
      "\u001b[2K    Uninstalling pandas-2.3.3:━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m71/91\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.3m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m71/91\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m71/91\u001b[0m [pandas]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.3.90[0m \u001b[32m71/91\u001b[0m [pandas]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.3.90:m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m71/91\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90━\u001b[0m \u001b[32m71/91\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: huggingface_hub\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m72/91\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: huggingface-hub 0.36.0━━━━━━━\u001b[0m \u001b[32m72/91\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling huggingface-hub-0.36.0:[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m72/91\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled huggingface-hub-0.36.0m━━━━━━━━\u001b[0m \u001b[32m72/91\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: httpx━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]]\n",
      "\u001b[2K    Found existing installation: httpx 0.28.1╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling httpx-0.28.1:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled httpx-0.28.10m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]\n",
      "\u001b[2K  Attempting uninstall: aiohttp━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Found existing installation: aiohttp 3.13.2[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]\n",
      "\u001b[2K    Uninstalling aiohttp-3.13.2:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]\n",
      "\u001b[2K      Successfully uninstalled aiohttp-3.13.2╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m73/91\u001b[0m [huggingface_hub]\n",
      "\u001b[2K  Attempting uninstall: tyro━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m75/91\u001b[0m [aiohttp]hub]\n",
      "\u001b[2K    Found existing installation: tyro 0.9.35m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m75/91\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling tyro-0.9.35:━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m75/91\u001b[0m [aiohttp]\n",
      "\u001b[2K      Successfully uninstalled tyro-0.9.3591m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m75/91\u001b[0m [aiohttp]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m75/91\u001b[0m [aiohttp]\n",
      "\u001b[2K    Found existing installation: torch 2.8.0m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m75/91\u001b[0m [aiohttp]\n",
      "\u001b[2K    Uninstalling torch-2.8.0:━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.8.0[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: tokenizers━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.22.1m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling tokenizers-0.22.1:━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.22.1[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: diffusers━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: diffusers 0.35.20m\u001b[90m━━━━━━\u001b[0m \u001b[32m77/91\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling diffusers-0.35.2:━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m79/91\u001b[0m [diffusers]\n",
      "\u001b[2K      Successfully uninstalled diffusers-0.35.2╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m79/91\u001b[0m [diffusers]\n",
      "\u001b[2K  Attempting uninstall: xformers━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m79/91\u001b[0m [diffusers]\n",
      "\u001b[2K    Found existing installation: xformers 0.0.32.post290m━━━━━\u001b[0m \u001b[32m79/91\u001b[0m [diffusers]\n",
      "\u001b[2K    Uninstalling xformers-0.0.32.post2:[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m79/91\u001b[0m [diffusers]\n",
      "\u001b[2K      Successfully uninstalled xformers-0.0.32.post2\u001b[90m━━━━━\u001b[0m \u001b[32m79/91\u001b[0m [diffusers]\n",
      "\u001b[2K  Attempting uninstall: transformers━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m80/91\u001b[0m [xformers]\n",
      "\u001b[2K    Found existing installation: transformers 4.56.2m\u001b[90m━━━━\u001b[0m \u001b[32m80/91\u001b[0m [xformers]\n",
      "\u001b[2K    Uninstalling transformers-4.56.2:━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m81/91\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-4.56.2[0m\u001b[90m━━━━\u001b[0m \u001b[32m81/91\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m81/91\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: torchvision 0.23.00m\u001b[90m━━━━\u001b[0m \u001b[32m81/91\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torchvision-0.23.0:━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m81/91\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.23.0\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m81/91\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: datasets━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m82/91\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: datasets 4.3.00m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m82/91\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling datasets-4.3.0:━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m82/91\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.3.0[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m82/91\u001b[0m [torchvision]\n",
      "\u001b[2K  Attempting uninstall: cut_cross_entropy━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K    Found existing installation: cut-cross-entropy 25.1.10m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K    Uninstalling cut-cross-entropy-25.1.1:0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K      Successfully uninstalled cut-cross-entropy-25.1.1[90m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K  Attempting uninstall: bitsandbytes━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K    Found existing installation: bitsandbytes 0.48.20m\u001b[90m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K    Uninstalling bitsandbytes-0.48.2:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K      Successfully uninstalled bitsandbytes-0.48.2\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m83/91\u001b[0m [datasets]\n",
      "\u001b[2K  Attempting uninstall: accelerate━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m85/91\u001b[0m [bitsandbytes]\n",
      "\u001b[2K    Found existing installation: accelerate 1.11.0╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m85/91\u001b[0m [bitsandbytes]\n",
      "\u001b[2K    Uninstalling accelerate-1.11.0:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m85/91\u001b[0m [bitsandbytes]\n",
      "\u001b[2K      Successfully uninstalled accelerate-1.11.00m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m85/91\u001b[0m [bitsandbytes]\n",
      "\u001b[2K  Attempting uninstall: peft━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m86/91\u001b[0m [accelerate]\n",
      "\u001b[2K    Found existing installation: peft 0.17.1m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m86/91\u001b[0m [accelerate]\n",
      "\u001b[2K    Uninstalling peft-0.17.1:━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m86/91\u001b[0m [accelerate]\n",
      "\u001b[2K      Successfully uninstalled peft-0.17.1[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m86/91\u001b[0m [accelerate]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91/91\u001b[0m [unsloth][unsloth][peft]e]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.3 accelerate-1.11.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.11.0 attrs-25.4.0 bitsandbytes-0.48.2 certifi-2025.10.5 charset_normalizer-3.4.4 cut_cross_entropy-25.1.1 datasets-4.3.0 diffusers-0.35.2 dill-0.4.0 docstring-parser-0.17.0 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.9.0 h11-0.16.0 hf-xet-1.2.0 hf_transfer-0.1.9 httpcore-1.0.9 httpx-0.28.1 huggingface_hub-0.36.0 idna-3.11 importlib_metadata-8.7.0 jinja2-3.1.6 markdown-it-py-4.0.0 mdurl-0.1.2 mpmath-1.3.0 msgspec-0.19.0 multidict-6.7.0 multiprocess-0.70.16 networkx-3.5 numpy-2.3.4 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 packaging-25.0 pandas-2.3.3 peft-0.17.1 pillow-12.0.0 propcache-0.4.1 protobuf-6.33.0 psutil-7.1.3 pyarrow-22.0.0 pygments-2.19.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 regex-2025.10.23 requests-2.32.5 rich-14.2.0 safetensors-0.6.2 sentencepiece-0.2.1 setuptools-80.9.0 shtab-1.7.2 six-1.17.0 sniffio-1.3.1 sympy-1.14.0 tokenizers-0.22.1 torch-2.8.0 torchao-0.14.1 torchvision-0.23.0 tqdm-4.67.1 transformers-4.56.2 triton-3.4.0 trl-0.16.1 typeguard-4.4.4 typing-extensions-4.15.0 tyro-0.9.35 tzdata-2025.2 unsloth-2025.10.8 unsloth_zoo-2025.10.9 urllib3-2.5.0 wheel-0.45.1 xformers-0.0.32.post2 xxhash-3.6.0 yarl-1.22.0 zipp-3.23.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Installed. Python: 3.12.11 | packaged by conda-forge | (main, Jun  4 2025, 14:45:31) [GCC 13.3.0]\n",
      "Please now go to: Runtime -> Restart runtime, then re-run the next cell.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip uninstall -y unsloth unsloth_zoo trl\n",
    "%pip install --upgrade --force-reinstall --no-cache-dir \"trl>=0.14,<0.17\" unsloth unsloth_zoo\n",
    "\n",
    "import IPython, sys\n",
    "print(\"Installed. Python:\", sys.version)\n",
    "print(\"Please now go to: Runtime -> Restart runtime, then re-run the next cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573dd8c3-68f9-402d-8ed4-6507c73e6e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.11 | packaged by conda-forge | (main, Jun  4 2025, 14:45:31) [GCC 13.3.0]\n",
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "unsloth = 2025.10.8\n",
      "transformers = 4.56.2\n",
      "trl = 0.16.1\n",
      "has align_logprobs_with_mask: False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "\n",
    "import unsloth, transformers, trl\n",
    "print(\"unsloth =\", getattr(unsloth, \"__version__\", \"?\"))\n",
    "print(\"transformers =\", transformers.__version__)\n",
    "print(\"trl =\", trl.__version__)\n",
    "\n",
    "import importlib\n",
    "rl = importlib.import_module(\"unsloth.models.rl\")\n",
    "print(\"has align_logprobs_with_mask:\", \"align_logprobs_with_mask\" in rl.RL_REPLACEMENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac2ecbb-f0f4-4c42-88d5-3ed854e66302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.10.8: Fast Llama patching. Transformers: 4.56.2.\n",
      "   \\\\   /|    NVIDIA H100 80GB HBM3. Num GPUs = 1. Max memory: 79.179 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 1024  # maximum sequence length for inputs\n",
    "dtype = None  # auto-select optimal dtype based on gpu capability\n",
    "load_in_4bit = True  # enable 4-bit quantization to reduce memory usage\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",  # base model for fine-tuning\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcf854d-582b-4153-ba9e-e09ee6f2630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "full_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\", split=\"train\")\n",
    "\n",
    "shuffled_dataset = full_dataset.shuffle(seed=42)\n",
    "train_dataset = shuffled_dataset.select(range(20000))\n",
    "validation_dataset = shuffled_dataset.select(range(20000, 22000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c77b56-fefc-4775-8525-440e57d8997d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37052e70b27d46238039e0524e8cd777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_prompt = \"\"\"You are a great and STRICT mathematician. Your task is to see and judge if the proposed Solution solves the Question correctly. You are to respond with EXACTLY one word on a single line. You are to respond with either 'True' if the solution is correct or 'False' if the solution is NOT correct. DO NOT ADD ANY PUNCTUATION OR ANY OTHER TEXT OTHER THAN 'True' or 'False'.\n",
    "\n",
    "Question:\n",
    "{}\n",
    "\n",
    "Solution:\n",
    "{}\n",
    "\n",
    "Output:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    questions = examples[\"question\"]\n",
    "    solutions = examples[\"solution\"]\n",
    "    outputs = examples[\"is_correct\"]\n",
    "    texts = []\n",
    "    for question, solution, output in zip(questions, solutions, outputs):\n",
    "        text = training_prompt.format(question, str(solution), str(output)) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts }\n",
    "\n",
    "formatted_train_dataset = train_dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92afdc45-8ed6-41cc-b814-f7b7407e2ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.10.8 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 32,  # lora rank determines adapter capacity, 32 provides good balance\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],  # attention and mlp layers to adapt\n",
    "    lora_alpha = 64,  # scaling factor, typically 2x rank for balanced adaptation\n",
    "    lora_dropout = 0.05,  # low dropout to maintain performance while regularizing\n",
    "    bias = \"none\",  # no bias terms trained to reduce parameters\n",
    "    use_gradient_checkpointing = \"unsloth\",  # memory efficient training\n",
    "    random_state = 42,  # reproducibility seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badfe016-4376-4b37-b4a9-b53b9349eb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e331ff113a084c78aa8d21c812a5b972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=228):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = formatted_train_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,  # small batch size to fit in h100 memory\n",
    "        num_train_epochs = 3,  # full passes through training data\n",
    "        gradient_accumulation_steps = 8,  # effective batch size is 2*8=16 per device\n",
    "        warmup_steps = 100,  # linear warmup for stable training start\n",
    "        learning_rate = 2e-4,  # standard lora learning rate\n",
    "        fp16 = not torch.cuda.is_bf16_supported(),  # use fp16 if bf16 not available\n",
    "        bf16 = torch.cuda.is_bf16_supported(),  # prefer bf16 for better numerical stability\n",
    "        logging_steps = 20,  # log metrics every 20 steps\n",
    "        optim = \"adamw_8bit\",  # memory efficient optimizer\n",
    "        weight_decay = 0.05,  # l2 regularization to prevent overfitting\n",
    "        lr_scheduler_type = \"cosine\",  # cosine annealing for smooth decay\n",
    "        seed = 42,  # random seed for reproducibility\n",
    "        output_dir = \"outputs\",  # directory for checkpoints\n",
    "        report_to = \"none\",  # disable external logging services\n",
    "        save_strategy = \"epoch\",  # save model after each epoch\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efa62c9f-2de5-4e19-ab5d-3852ef75bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,000 | Num Epochs = 3 | Total steps = 3,750\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 8\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 8 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 83,886,080 of 8,114,147,328 (1.03% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 2:39:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.389500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.758300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.626200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.619700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.641600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.615400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.617900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.639200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.608300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.620600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.616600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.605100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.603800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.608300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.598400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.594400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.576500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.628900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.577200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.599500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.579800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.584200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.567400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.561500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.593100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.579600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.582600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.586600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.572900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.556400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.574400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.542700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.558700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.531100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.558700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.556300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.548500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.524400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.523000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.563400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.545900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.543400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.545700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.438900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>0.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>0.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>0.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>0.423500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.410400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>0.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>0.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>0.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>0.448300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.446200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>0.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>0.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>0.434500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>0.417600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>0.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>0.435900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>0.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>0.458300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.420300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>0.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>0.399400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>0.413900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>0.426800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>0.435000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>0.406300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>0.411800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>0.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.403100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>0.407700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>0.410700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>0.389000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.393300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>0.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>0.397500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>0.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>0.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.404500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>0.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>0.404600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>0.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>0.399700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>0.394300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.404800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>0.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>0.406400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.402800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>0.381500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>0.393700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>0.387700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>0.386300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.401200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>0.384700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>0.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>0.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>0.394600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.379000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>0.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>0.269400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.266900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>0.267700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>0.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>0.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>0.265600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>0.263100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.311500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>0.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>0.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.269000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>0.286200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>0.293100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>0.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>0.266700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.279600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>0.268400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>0.272000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>0.276900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.269100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>0.277400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>0.268100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>0.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>0.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.264800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>0.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>0.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>0.273300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>0.273100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.276800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>0.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>0.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>0.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>0.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>0.269900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>0.277200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>0.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.280400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>0.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>0.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>0.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.267000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>0.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>0.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>0.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>0.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>0.262800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>0.266900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>0.257200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>0.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.261100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>0.273000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>0.259700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.4264144443511963, metrics={'train_runtime': 9577.4127, 'train_samples_per_second': 6.265, 'train_steps_per_second': 0.392, 'total_flos': 1.0790728835110502e+18, 'train_loss': 0.4264144443511963})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a2c16-e8ea-4d7f-add1-1d032fab46ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### QUESTION ####\n",
      "How many unordered pairs of prime numbers have a sum of 40?\n",
      "\n",
      "#### SOLUTION ####\n",
      "To compute all the prime numbers with sum of 40, we can enumerate all pairs of primes where sum = 40. \n",
      "One such instance can be solved by enumeration as follows:\n",
      "<llm-code>\n",
      "import itertools\n",
      "\n",
      "answer = []\n",
      "# Max sum of two primes below 40 is 39, so limiting ourselves to that\n",
      "# Prevents us from examining the same pairing (i.e., [3,39]) again\n",
      "for p1, p2 in itertools.product(range(2,20), range(2,39)):\n",
      "    if p1 + p2 == 40:\n",
      "        answer.append((p1, p2))\n",
      "\n",
      "print(len(answer))\n",
      "</llm-code>\n",
      "<llm-code-output>\n",
      "18\n",
      "</llm-code-output>\n",
      "Hence, there are \\boxed{18} unordered pairs of prime numbers that have a sum of 40.\n",
      "\n",
      "#### MODEL'S PREDICTION ####\n",
      "False\n",
      "\n",
      "#### CORRECT ANSWER ####\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "inference_prompt = \"\"\"You are a great and STRICT mathematician. Your task is to see and judge if the proposed Solution solves the Question correctly. You are to respond with EXACTLY one word on a single line. You are to respond with either 'True' if the solution is correct or 'False' if the solution is NOT correct. DO NOT ADD ANY PUNCTUATION OR ANY OTHER TEXT OTHER THAN 'True' or 'False'.\n",
    "\n",
    "Question:\n",
    "{}\n",
    "\n",
    "Solution:\n",
    "{}\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "example = validation_dataset[10]\n",
    "question = example[\"question\"]\n",
    "solution = example[\"solution\"]\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    inference_prompt.format(question, str(solution))\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 1, do_sample = False, temperature = 0.0, pad_token_id = tokenizer.eos_token_id, eos_token_id = tokenizer.eos_token_id, use_cache = True)\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "\n",
    "print(\"#### QUESTION ####\")\n",
    "print(question)\n",
    "print(\"\\n#### SOLUTION ####\")\n",
    "print(solution)\n",
    "print(\"\\n#### MODEL'S PREDICTION ####\")\n",
    "print(response[0].split(\"Output:\\n\")[1])\n",
    "print(\"\\n#### CORRECT ANSWER ####\")\n",
    "print(example[\"is_correct\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39462930-83c1-4a28-a952-ad1b5ab4bcbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1063/10000 [01:44<14:22, 10.37it/s]Unsloth: Input IDs of shape torch.Size([1, 1067]) with length 1067 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 13%|█▎        | 1274/10000 [02:05<14:13, 10.22it/s]Unsloth: Input IDs of shape torch.Size([1, 1234]) with length 1234 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 16%|█▌        | 1572/10000 [02:34<14:06,  9.96it/s]Unsloth: Input IDs of shape torch.Size([1, 1076]) with length 1076 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 16%|█▌        | 1590/10000 [02:36<13:59, 10.01it/s]Unsloth: Input IDs of shape torch.Size([1, 1047]) with length 1047 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 23%|██▎       | 2328/10000 [03:49<12:20, 10.36it/s]Unsloth: Input IDs of shape torch.Size([1, 1249]) with length 1249 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 30%|███       | 3050/10000 [05:01<11:30, 10.07it/s]Unsloth: Input IDs of shape torch.Size([1, 1293]) with length 1293 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 32%|███▎      | 3250/10000 [05:21<11:16,  9.99it/s]Unsloth: Input IDs of shape torch.Size([1, 1087]) with length 1087 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 33%|███▎      | 3320/10000 [05:28<11:08,  9.99it/s]Unsloth: Input IDs of shape torch.Size([1, 1188]) with length 1188 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 35%|███▌      | 3546/10000 [05:50<10:41, 10.06it/s]Unsloth: Input IDs of shape torch.Size([1, 1344]) with length 1344 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 40%|███▉      | 3987/10000 [06:33<09:25, 10.63it/s]Unsloth: Input IDs of shape torch.Size([1, 1098]) with length 1098 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 46%|████▌     | 4584/10000 [07:32<08:53, 10.15it/s]Unsloth: Input IDs of shape torch.Size([1, 1100]) with length 1100 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 54%|█████▍    | 5412/10000 [08:54<07:39,  9.99it/s]Unsloth: Input IDs of shape torch.Size([1, 1357]) with length 1357 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 58%|█████▊    | 5828/10000 [09:36<06:56, 10.01it/s]Unsloth: Input IDs of shape torch.Size([1, 1039]) with length 1039 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 59%|█████▉    | 5943/10000 [09:47<06:45, 10.00it/s]Unsloth: Input IDs of shape torch.Size([1, 1223]) with length 1223 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 64%|██████▍   | 6440/10000 [10:37<05:50, 10.15it/s]Unsloth: Input IDs of shape torch.Size([1, 1113]) with length 1113 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 66%|██████▌   | 6559/10000 [10:49<05:44, 10.00it/s]Unsloth: Input IDs of shape torch.Size([1, 1306]) with length 1306 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 66%|██████▌   | 6620/10000 [10:55<05:39,  9.95it/s]Unsloth: Input IDs of shape torch.Size([1, 1271]) with length 1271 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 69%|██████▊   | 6868/10000 [11:19<04:59, 10.46it/s]Unsloth: Input IDs of shape torch.Size([1, 1027]) with length 1027 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 78%|███████▊  | 7762/10000 [12:47<03:27, 10.77it/s]Unsloth: Input IDs of shape torch.Size([1, 1068]) with length 1068 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 80%|███████▉  | 7964/10000 [13:07<03:10, 10.66it/s]Unsloth: Input IDs of shape torch.Size([1, 1195]) with length 1195 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 97%|█████████▋| 9673/10000 [15:52<00:33,  9.65it/s]Unsloth: Input IDs of shape torch.Size([1, 1141]) with length 1141 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      " 98%|█████████▊| 9765/10000 [16:02<00:21, 10.77it/s]Unsloth: Input IDs of shape torch.Size([1, 1085]) with length 1085 > the model's max sequence length of 1024.\n",
      "We shall truncate it ourselves. It's imperative if you correct this issue first.\n",
      "100%|██████████| 10000/10000 [16:24<00:00, 10.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission file 'submission.csv' created successfully!\n",
      "You can now download this file and submit it to the Kaggle competition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "test_dataset = load_dataset(\"ad6398/nyu-dl-teach-maths-comp\", split=\"test\")\n",
    "predictions = []\n",
    "\n",
    "def parse_output(response_text):\n",
    "    output_part = response_text.split(\"Output:\\n\")[-1]\n",
    "    if 'true' in output_part.lower():\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "for example in tqdm(test_dataset):\n",
    "    question = example[\"question\"]\n",
    "    solution = example[\"solution\"]\n",
    "\n",
    "    prompt = inference_prompt.format(question, str(solution))\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 1, do_sample = False, temperature = 0.0, pad_token_id = tokenizer.eos_token_id, eos_token_id = tokenizer.eos_token_id, use_cache = True)\n",
    "    response_text = tokenizer.batch_decode(outputs)[0]\n",
    "\n",
    "    prediction = parse_output(response_text)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': range(len(predictions)),\n",
    "    'is_correct': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nSubmission file 'submission.csv' created successfully!\")\n",
    "print(\"You can now download this file and submit it to the Kaggle competition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fb0ad-37eb-4896-aa69-890800010a71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (main venv)",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
