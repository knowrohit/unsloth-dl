{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "grad_norm": 0.42847388982772827,
      "learning_rate": 9.882510013351135e-05,
      "loss": 0.8778,
      "step": 50
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4465162754058838,
      "learning_rate": 9.748998664886516e-05,
      "loss": 0.709,
      "step": 100
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.41149336099624634,
      "learning_rate": 9.615487316421896e-05,
      "loss": 0.7029,
      "step": 150
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.40224599838256836,
      "learning_rate": 9.481975967957278e-05,
      "loss": 0.7269,
      "step": 200
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.4298059046268463,
      "learning_rate": 9.348464619492658e-05,
      "loss": 0.7062,
      "step": 250
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.377262681722641,
      "learning_rate": 9.214953271028038e-05,
      "loss": 0.6889,
      "step": 300
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3450877070426941,
      "learning_rate": 9.081441922563419e-05,
      "loss": 0.6881,
      "step": 350
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.4000623822212219,
      "learning_rate": 8.947930574098799e-05,
      "loss": 0.6745,
      "step": 400
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.4251692295074463,
      "learning_rate": 8.814419225634179e-05,
      "loss": 0.6816,
      "step": 450
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.35269439220428467,
      "learning_rate": 8.680907877169559e-05,
      "loss": 0.6658,
      "step": 500
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.3366101086139679,
      "learning_rate": 8.54739652870494e-05,
      "loss": 0.683,
      "step": 550
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.5217921733856201,
      "learning_rate": 8.41388518024032e-05,
      "loss": 0.6703,
      "step": 600
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.36145704984664917,
      "learning_rate": 8.280373831775702e-05,
      "loss": 0.6771,
      "step": 650
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.344753623008728,
      "learning_rate": 8.146862483311082e-05,
      "loss": 0.659,
      "step": 700
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.39573541283607483,
      "learning_rate": 8.013351134846462e-05,
      "loss": 0.6691,
      "step": 750
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.45842084288597107,
      "learning_rate": 7.879839786381843e-05,
      "loss": 0.6596,
      "step": 800
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3821866512298584,
      "learning_rate": 7.746328437917223e-05,
      "loss": 0.6697,
      "step": 850
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.4388541877269745,
      "learning_rate": 7.612817089452604e-05,
      "loss": 0.6701,
      "step": 900
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.553843080997467,
      "learning_rate": 7.479305740987984e-05,
      "loss": 0.6645,
      "step": 950
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4527105987071991,
      "learning_rate": 7.345794392523366e-05,
      "loss": 0.6499,
      "step": 1000
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.49427148699760437,
      "learning_rate": 7.212283044058746e-05,
      "loss": 0.6614,
      "step": 1050
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4178614914417267,
      "learning_rate": 7.078771695594127e-05,
      "loss": 0.6633,
      "step": 1100
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.3969365358352661,
      "learning_rate": 6.945260347129507e-05,
      "loss": 0.6436,
      "step": 1150
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.43888285756111145,
      "learning_rate": 6.811748998664887e-05,
      "loss": 0.6662,
      "step": 1200
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.44097816944122314,
      "learning_rate": 6.678237650200267e-05,
      "loss": 0.6519,
      "step": 1250
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.48172569274902344,
      "learning_rate": 6.544726301735647e-05,
      "loss": 0.558,
      "step": 1300
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5555459856987,
      "learning_rate": 6.411214953271028e-05,
      "loss": 0.5745,
      "step": 1350
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5163300037384033,
      "learning_rate": 6.277703604806408e-05,
      "loss": 0.5736,
      "step": 1400
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5806172490119934,
      "learning_rate": 6.14419225634179e-05,
      "loss": 0.577,
      "step": 1450
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.6470587849617004,
      "learning_rate": 6.0106809078771696e-05,
      "loss": 0.5537,
      "step": 1500
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.5027607083320618,
      "learning_rate": 5.877169559412551e-05,
      "loss": 0.5744,
      "step": 1550
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5191686749458313,
      "learning_rate": 5.743658210947931e-05,
      "loss": 0.5593,
      "step": 1600
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.5725610852241516,
      "learning_rate": 5.610146862483311e-05,
      "loss": 0.5854,
      "step": 1650
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.5446178317070007,
      "learning_rate": 5.476635514018692e-05,
      "loss": 0.5511,
      "step": 1700
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5289411544799805,
      "learning_rate": 5.343124165554072e-05,
      "loss": 0.5602,
      "step": 1750
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.49646350741386414,
      "learning_rate": 5.209612817089453e-05,
      "loss": 0.5708,
      "step": 1800
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.6082926392555237,
      "learning_rate": 5.076101468624833e-05,
      "loss": 0.5558,
      "step": 1850
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5215615630149841,
      "learning_rate": 4.9425901201602136e-05,
      "loss": 0.5538,
      "step": 1900
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.6236454844474792,
      "learning_rate": 4.809078771695594e-05,
      "loss": 0.5446,
      "step": 1950
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6370816230773926,
      "learning_rate": 4.675567423230975e-05,
      "loss": 0.5501,
      "step": 2000
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.7290992140769958,
      "learning_rate": 4.5420560747663556e-05,
      "loss": 0.5493,
      "step": 2050
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.6814956665039062,
      "learning_rate": 4.408544726301736e-05,
      "loss": 0.5274,
      "step": 2100
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.7019141912460327,
      "learning_rate": 4.275033377837116e-05,
      "loss": 0.5509,
      "step": 2150
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6828774213790894,
      "learning_rate": 4.141522029372497e-05,
      "loss": 0.5389,
      "step": 2200
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.7184171676635742,
      "learning_rate": 4.008010680907877e-05,
      "loss": 0.5299,
      "step": 2250
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.7121848464012146,
      "learning_rate": 3.8744993324432575e-05,
      "loss": 0.5501,
      "step": 2300
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.7249907851219177,
      "learning_rate": 3.740987983978638e-05,
      "loss": 0.5451,
      "step": 2350
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.635041356086731,
      "learning_rate": 3.607476635514019e-05,
      "loss": 0.5576,
      "step": 2400
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.660753607749939,
      "learning_rate": 3.4739652870493996e-05,
      "loss": 0.5568,
      "step": 2450
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5418767333030701,
      "learning_rate": 3.34045393858478e-05,
      "loss": 0.5284,
      "step": 2500
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.6570726037025452,
      "learning_rate": 3.20694259012016e-05,
      "loss": 0.4396,
      "step": 2550
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.8614078164100647,
      "learning_rate": 3.073431241655541e-05,
      "loss": 0.4324,
      "step": 2600
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6731128692626953,
      "learning_rate": 2.9399198931909212e-05,
      "loss": 0.4438,
      "step": 2650
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.8526785373687744,
      "learning_rate": 2.8064085447263015e-05,
      "loss": 0.4444,
      "step": 2700
    },
    {
      "epoch": 2.2,
      "grad_norm": 1.034263253211975,
      "learning_rate": 2.6728971962616822e-05,
      "loss": 0.4391,
      "step": 2750
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.9058825373649597,
      "learning_rate": 2.539385847797063e-05,
      "loss": 0.434,
      "step": 2800
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.6560150980949402,
      "learning_rate": 2.4058744993324432e-05,
      "loss": 0.4413,
      "step": 2850
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.7785441875457764,
      "learning_rate": 2.272363150867824e-05,
      "loss": 0.432,
      "step": 2900
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7597134709358215,
      "learning_rate": 2.1388518024032045e-05,
      "loss": 0.462,
      "step": 2950
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.6788946986198425,
      "learning_rate": 2.005340453938585e-05,
      "loss": 0.4534,
      "step": 3000
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.613195538520813,
      "learning_rate": 1.8718291054739652e-05,
      "loss": 0.4366,
      "step": 3050
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.9719125628471375,
      "learning_rate": 1.738317757009346e-05,
      "loss": 0.4355,
      "step": 3100
    },
    {
      "epoch": 2.52,
      "grad_norm": 1.0229040384292603,
      "learning_rate": 1.6048064085447265e-05,
      "loss": 0.446,
      "step": 3150
    },
    {
      "epoch": 2.56,
      "grad_norm": 1.0333019495010376,
      "learning_rate": 1.4712950600801067e-05,
      "loss": 0.4483,
      "step": 3200
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.8833162188529968,
      "learning_rate": 1.3377837116154874e-05,
      "loss": 0.4266,
      "step": 3250
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7412859797477722,
      "learning_rate": 1.2042723631508679e-05,
      "loss": 0.4416,
      "step": 3300
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7831760048866272,
      "learning_rate": 1.0707610146862484e-05,
      "loss": 0.4327,
      "step": 3350
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.9380245208740234,
      "learning_rate": 9.372496662216289e-06,
      "loss": 0.4256,
      "step": 3400
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.8738373517990112,
      "learning_rate": 8.037383177570095e-06,
      "loss": 0.4196,
      "step": 3450
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.7412367463111877,
      "learning_rate": 6.702269692923899e-06,
      "loss": 0.4294,
      "step": 3500
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.9855321645736694,
      "learning_rate": 5.3671562082777036e-06,
      "loss": 0.4354,
      "step": 3550
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.9198365807533264,
      "learning_rate": 4.0320427236315086e-06,
      "loss": 0.433,
      "step": 3600
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.7200182676315308,
      "learning_rate": 2.696929238985314e-06,
      "loss": 0.4242,
      "step": 3650
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.9494790434837341,
      "learning_rate": 1.361815754339119e-06,
      "loss": 0.4482,
      "step": 3700
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7408268451690674,
      "learning_rate": 2.67022696929239e-08,
      "loss": 0.4252,
      "step": 3750
    }
  ],
  "logging_steps": 50,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.8664690454573875e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
