{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 0.934662938117981,
      "learning_rate": 0.0001997863818424566,
      "loss": 1.0684,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.6203089356422424,
      "learning_rate": 0.00019925233644859814,
      "loss": 0.7432,
      "step": 20
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.6220654845237732,
      "learning_rate": 0.00019871829105473968,
      "loss": 0.715,
      "step": 30
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.6123958230018616,
      "learning_rate": 0.0001981842456608812,
      "loss": 0.7737,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.488129585981369,
      "learning_rate": 0.0001976502002670227,
      "loss": 0.741,
      "step": 50
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.7219635248184204,
      "learning_rate": 0.00019711615487316423,
      "loss": 0.7541,
      "step": 60
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.5222311019897461,
      "learning_rate": 0.00019658210947930574,
      "loss": 0.7491,
      "step": 70
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.5352159738540649,
      "learning_rate": 0.00019604806408544728,
      "loss": 0.6974,
      "step": 80
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.4971642792224884,
      "learning_rate": 0.0001955140186915888,
      "loss": 0.6872,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5792320966720581,
      "learning_rate": 0.00019497997329773033,
      "loss": 0.7227,
      "step": 100
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.5970219969749451,
      "learning_rate": 0.00019444592790387183,
      "loss": 0.7707,
      "step": 110
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.6969053745269775,
      "learning_rate": 0.00019391188251001334,
      "loss": 0.6938,
      "step": 120
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.748551070690155,
      "learning_rate": 0.00019337783711615488,
      "loss": 0.7478,
      "step": 130
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.6432809233665466,
      "learning_rate": 0.00019284379172229642,
      "loss": 0.702,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6153623461723328,
      "learning_rate": 0.00019230974632843793,
      "loss": 0.6969,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.6374168992042542,
      "learning_rate": 0.00019177570093457943,
      "loss": 0.7243,
      "step": 160
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.6156815886497498,
      "learning_rate": 0.00019124165554072097,
      "loss": 0.7341,
      "step": 170
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.5679386258125305,
      "learning_rate": 0.00019070761014686248,
      "loss": 0.8077,
      "step": 180
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.7783952951431274,
      "learning_rate": 0.00019017356475300402,
      "loss": 0.7606,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5913742780685425,
      "learning_rate": 0.00018963951935914555,
      "loss": 0.7138,
      "step": 200
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.723747193813324,
      "learning_rate": 0.00018910547396528706,
      "loss": 0.7409,
      "step": 210
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.5867549180984497,
      "learning_rate": 0.00018857142857142857,
      "loss": 0.7226,
      "step": 220
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.6455386877059937,
      "learning_rate": 0.00018803738317757008,
      "loss": 0.6949,
      "step": 230
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.6568281650543213,
      "learning_rate": 0.00018750333778371164,
      "loss": 0.7234,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.5639530420303345,
      "learning_rate": 0.00018696929238985315,
      "loss": 0.7556,
      "step": 250
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.6206154823303223,
      "learning_rate": 0.00018643524699599466,
      "loss": 0.6902,
      "step": 260
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.6170441508293152,
      "learning_rate": 0.0001859012016021362,
      "loss": 0.7233,
      "step": 270
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.6446903347969055,
      "learning_rate": 0.0001853671562082777,
      "loss": 0.7171,
      "step": 280
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.6935158967971802,
      "learning_rate": 0.00018483311081441924,
      "loss": 0.6887,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6025360226631165,
      "learning_rate": 0.00018429906542056075,
      "loss": 0.74,
      "step": 300
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.8077207207679749,
      "learning_rate": 0.0001837650200267023,
      "loss": 0.7379,
      "step": 310
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.6027359366416931,
      "learning_rate": 0.0001832309746328438,
      "loss": 0.6882,
      "step": 320
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.6297216415405273,
      "learning_rate": 0.0001826969292389853,
      "loss": 0.7422,
      "step": 330
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.6344595551490784,
      "learning_rate": 0.00018216288384512684,
      "loss": 0.7372,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.5695234537124634,
      "learning_rate": 0.00018162883845126838,
      "loss": 0.6546,
      "step": 350
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.5681860446929932,
      "learning_rate": 0.0001810947930574099,
      "loss": 0.6631,
      "step": 360
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.5976499915122986,
      "learning_rate": 0.0001805607476635514,
      "loss": 0.6741,
      "step": 370
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.5525160431861877,
      "learning_rate": 0.00018002670226969293,
      "loss": 0.7394,
      "step": 380
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.6332896947860718,
      "learning_rate": 0.00017949265687583444,
      "loss": 0.6647,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5879572033882141,
      "learning_rate": 0.00017895861148197598,
      "loss": 0.736,
      "step": 400
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.701088011264801,
      "learning_rate": 0.00017842456608811751,
      "loss": 0.6774,
      "step": 410
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.5582494139671326,
      "learning_rate": 0.00017789052069425902,
      "loss": 0.6925,
      "step": 420
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.5249173641204834,
      "learning_rate": 0.00017735647530040053,
      "loss": 0.749,
      "step": 430
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.7478209137916565,
      "learning_rate": 0.00017682242990654207,
      "loss": 0.7497,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.5634772777557373,
      "learning_rate": 0.00017628838451268358,
      "loss": 0.6738,
      "step": 450
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.6161753535270691,
      "learning_rate": 0.00017575433911882511,
      "loss": 0.7089,
      "step": 460
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.6488540768623352,
      "learning_rate": 0.00017522029372496662,
      "loss": 0.7267,
      "step": 470
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.6031270623207092,
      "learning_rate": 0.00017468624833110816,
      "loss": 0.6715,
      "step": 480
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.5633773803710938,
      "learning_rate": 0.00017415220293724967,
      "loss": 0.6445,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5441223382949829,
      "learning_rate": 0.00017361815754339118,
      "loss": 0.6874,
      "step": 500
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.706831693649292,
      "learning_rate": 0.00017308411214953274,
      "loss": 0.6792,
      "step": 510
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.6167113780975342,
      "learning_rate": 0.00017255006675567425,
      "loss": 0.7138,
      "step": 520
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.6788026094436646,
      "learning_rate": 0.00017201602136181576,
      "loss": 0.7043,
      "step": 530
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.7597652077674866,
      "learning_rate": 0.00017148197596795727,
      "loss": 0.7441,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.5746834874153137,
      "learning_rate": 0.0001709479305740988,
      "loss": 0.6726,
      "step": 550
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.8174303770065308,
      "learning_rate": 0.00017041388518024034,
      "loss": 0.7554,
      "step": 560
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.5521784424781799,
      "learning_rate": 0.00016987983978638185,
      "loss": 0.6836,
      "step": 570
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.6464346051216125,
      "learning_rate": 0.0001693457943925234,
      "loss": 0.6854,
      "step": 580
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.6267392039299011,
      "learning_rate": 0.0001688117489986649,
      "loss": 0.7064,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6862218379974365,
      "learning_rate": 0.0001682777036048064,
      "loss": 0.6552,
      "step": 600
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.6963757276535034,
      "learning_rate": 0.00016774365821094794,
      "loss": 0.7292,
      "step": 610
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.7088643312454224,
      "learning_rate": 0.00016720961281708948,
      "loss": 0.715,
      "step": 620
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.5905238389968872,
      "learning_rate": 0.000166675567423231,
      "loss": 0.7116,
      "step": 630
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.7522954940795898,
      "learning_rate": 0.0001661415220293725,
      "loss": 0.6548,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.6158803105354309,
      "learning_rate": 0.00016560747663551403,
      "loss": 0.688,
      "step": 650
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.5779266953468323,
      "learning_rate": 0.00016507343124165554,
      "loss": 0.6881,
      "step": 660
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.8341852426528931,
      "learning_rate": 0.00016453938584779708,
      "loss": 0.6966,
      "step": 670
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.6239646673202515,
      "learning_rate": 0.00016400534045393859,
      "loss": 0.6897,
      "step": 680
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.542096734046936,
      "learning_rate": 0.00016347129506008012,
      "loss": 0.6545,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.5910903215408325,
      "learning_rate": 0.00016293724966622163,
      "loss": 0.6301,
      "step": 700
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.7105690836906433,
      "learning_rate": 0.00016240320427236314,
      "loss": 0.713,
      "step": 710
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.5631331205368042,
      "learning_rate": 0.00016186915887850468,
      "loss": 0.7161,
      "step": 720
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.5814740657806396,
      "learning_rate": 0.0001613351134846462,
      "loss": 0.6558,
      "step": 730
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.6616711616516113,
      "learning_rate": 0.00016080106809078772,
      "loss": 0.7036,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.5716029405593872,
      "learning_rate": 0.00016026702269692923,
      "loss": 0.6761,
      "step": 750
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.6664098501205444,
      "learning_rate": 0.00015973297730307077,
      "loss": 0.7112,
      "step": 760
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.6009532809257507,
      "learning_rate": 0.00015919893190921228,
      "loss": 0.6453,
      "step": 770
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.6387380361557007,
      "learning_rate": 0.0001586648865153538,
      "loss": 0.6631,
      "step": 780
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.7263074517250061,
      "learning_rate": 0.00015813084112149535,
      "loss": 0.6622,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7209287285804749,
      "learning_rate": 0.00015759679572763686,
      "loss": 0.7012,
      "step": 800
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.7977433204650879,
      "learning_rate": 0.00015706275033377837,
      "loss": 0.7096,
      "step": 810
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.789146363735199,
      "learning_rate": 0.0001565287049399199,
      "loss": 0.6802,
      "step": 820
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.569033145904541,
      "learning_rate": 0.00015599465954606144,
      "loss": 0.7104,
      "step": 830
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.6075165867805481,
      "learning_rate": 0.00015546061415220295,
      "loss": 0.6729,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.6043212413787842,
      "learning_rate": 0.00015492656875834446,
      "loss": 0.6441,
      "step": 850
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.6424886584281921,
      "learning_rate": 0.000154392523364486,
      "loss": 0.7612,
      "step": 860
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.7517607808113098,
      "learning_rate": 0.0001538584779706275,
      "loss": 0.6725,
      "step": 870
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.7396725416183472,
      "learning_rate": 0.00015332443257676904,
      "loss": 0.6705,
      "step": 880
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.6751348972320557,
      "learning_rate": 0.00015279038718291055,
      "loss": 0.6749,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.7139243483543396,
      "learning_rate": 0.00015225634178905209,
      "loss": 0.6787,
      "step": 900
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.5694444179534912,
      "learning_rate": 0.0001517222963951936,
      "loss": 0.6752,
      "step": 910
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.6680419445037842,
      "learning_rate": 0.0001511882510013351,
      "loss": 0.6643,
      "step": 920
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.6801015734672546,
      "learning_rate": 0.00015065420560747664,
      "loss": 0.6697,
      "step": 930
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.7771345376968384,
      "learning_rate": 0.00015012016021361818,
      "loss": 0.7178,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.8234269618988037,
      "learning_rate": 0.00014958611481975968,
      "loss": 0.6998,
      "step": 950
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.6744822263717651,
      "learning_rate": 0.00014905206942590122,
      "loss": 0.6339,
      "step": 960
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.761803388595581,
      "learning_rate": 0.00014851802403204273,
      "loss": 0.7126,
      "step": 970
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.6729292273521423,
      "learning_rate": 0.00014798397863818424,
      "loss": 0.7032,
      "step": 980
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.7111127972602844,
      "learning_rate": 0.00014744993324432578,
      "loss": 0.6866,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6651653051376343,
      "learning_rate": 0.0001469158878504673,
      "loss": 0.6263,
      "step": 1000
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.748571515083313,
      "learning_rate": 0.00014638184245660882,
      "loss": 0.6703,
      "step": 1010
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.7354445457458496,
      "learning_rate": 0.00014584779706275033,
      "loss": 0.6524,
      "step": 1020
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.589397132396698,
      "learning_rate": 0.00014531375166889187,
      "loss": 0.828,
      "step": 1030
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.7338665127754211,
      "learning_rate": 0.00014477970627503338,
      "loss": 0.6415,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.8717567324638367,
      "learning_rate": 0.0001442456608811749,
      "loss": 0.666,
      "step": 1050
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.7252480983734131,
      "learning_rate": 0.00014371161548731642,
      "loss": 0.6889,
      "step": 1060
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.6949223279953003,
      "learning_rate": 0.00014317757009345796,
      "loss": 0.6996,
      "step": 1070
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.6784842610359192,
      "learning_rate": 0.00014264352469959947,
      "loss": 0.6666,
      "step": 1080
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.6481319665908813,
      "learning_rate": 0.000142109479305741,
      "loss": 0.6732,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.7559579610824585,
      "learning_rate": 0.00014157543391188254,
      "loss": 0.6552,
      "step": 1100
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.8122060298919678,
      "learning_rate": 0.00014104138851802405,
      "loss": 0.6437,
      "step": 1110
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.6740579605102539,
      "learning_rate": 0.00014050734312416556,
      "loss": 0.7036,
      "step": 1120
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.6167720556259155,
      "learning_rate": 0.00013997329773030707,
      "loss": 0.6211,
      "step": 1130
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.6899400949478149,
      "learning_rate": 0.0001394392523364486,
      "loss": 0.6118,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.668795108795166,
      "learning_rate": 0.00013890520694259014,
      "loss": 0.6842,
      "step": 1150
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.5910441875457764,
      "learning_rate": 0.00013837116154873165,
      "loss": 0.6316,
      "step": 1160
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.9316127896308899,
      "learning_rate": 0.00013783711615487318,
      "loss": 0.702,
      "step": 1170
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.6463952660560608,
      "learning_rate": 0.0001373030707610147,
      "loss": 0.6595,
      "step": 1180
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.6581971049308777,
      "learning_rate": 0.0001367690253671562,
      "loss": 0.6751,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6502552032470703,
      "learning_rate": 0.00013623497997329774,
      "loss": 0.7068,
      "step": 1200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.6581138968467712,
      "learning_rate": 0.00013570093457943927,
      "loss": 0.6277,
      "step": 1210
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.6370900273323059,
      "learning_rate": 0.00013516688918558078,
      "loss": 0.6371,
      "step": 1220
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.7163563966751099,
      "learning_rate": 0.0001346328437917223,
      "loss": 0.6466,
      "step": 1230
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.7271537184715271,
      "learning_rate": 0.00013409879839786383,
      "loss": 0.699,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7391752600669861,
      "learning_rate": 0.00013356475300400534,
      "loss": 0.6852,
      "step": 1250
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.9041561484336853,
      "learning_rate": 0.00013303070761014687,
      "loss": 0.4499,
      "step": 1260
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.7937576770782471,
      "learning_rate": 0.00013249666221628838,
      "loss": 0.4654,
      "step": 1270
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.8232129812240601,
      "learning_rate": 0.00013196261682242992,
      "loss": 0.4474,
      "step": 1280
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.8842138648033142,
      "learning_rate": 0.00013142857142857143,
      "loss": 0.4423,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.6649200916290283,
      "learning_rate": 0.00013089452603471294,
      "loss": 0.4867,
      "step": 1300
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.8165854215621948,
      "learning_rate": 0.0001303604806408545,
      "loss": 0.4651,
      "step": 1310
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.5993281006813049,
      "learning_rate": 0.000129826435246996,
      "loss": 0.4695,
      "step": 1320
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.7871865034103394,
      "learning_rate": 0.00012929238985313752,
      "loss": 0.4847,
      "step": 1330
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.8058184385299683,
      "learning_rate": 0.00012875834445927903,
      "loss": 0.473,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.7902940511703491,
      "learning_rate": 0.00012822429906542056,
      "loss": 0.4861,
      "step": 1350
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.8861064910888672,
      "learning_rate": 0.0001276902536715621,
      "loss": 0.4659,
      "step": 1360
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.9488266110420227,
      "learning_rate": 0.0001271562082777036,
      "loss": 0.4826,
      "step": 1370
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.7077959775924683,
      "learning_rate": 0.00012662216288384515,
      "loss": 0.5034,
      "step": 1380
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.813722550868988,
      "learning_rate": 0.00012608811748998666,
      "loss": 0.4594,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.839784562587738,
      "learning_rate": 0.00012555407209612816,
      "loss": 0.4802,
      "step": 1400
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.7075783610343933,
      "learning_rate": 0.0001250200267022697,
      "loss": 0.4975,
      "step": 1410
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.8132374286651611,
      "learning_rate": 0.00012448598130841124,
      "loss": 0.5079,
      "step": 1420
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.6793340444564819,
      "learning_rate": 0.00012395193591455275,
      "loss": 0.4732,
      "step": 1430
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.7173762917518616,
      "learning_rate": 0.00012341789052069426,
      "loss": 0.4728,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.7688084244728088,
      "learning_rate": 0.0001228838451268358,
      "loss": 0.4775,
      "step": 1450
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.746539294719696,
      "learning_rate": 0.0001223497997329773,
      "loss": 0.4347,
      "step": 1460
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.7101253271102905,
      "learning_rate": 0.00012181575433911882,
      "loss": 0.4544,
      "step": 1470
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.8294172883033752,
      "learning_rate": 0.00012128170894526036,
      "loss": 0.4767,
      "step": 1480
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.7747626304626465,
      "learning_rate": 0.00012074766355140188,
      "loss": 0.481,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.8516771197319031,
      "learning_rate": 0.00012021361815754339,
      "loss": 0.4462,
      "step": 1500
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.7994239330291748,
      "learning_rate": 0.00011967957276368491,
      "loss": 0.4894,
      "step": 1510
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.9692401885986328,
      "learning_rate": 0.00011914552736982645,
      "loss": 0.5051,
      "step": 1520
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.7964989542961121,
      "learning_rate": 0.00011861148197596796,
      "loss": 0.4732,
      "step": 1530
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.8986838459968567,
      "learning_rate": 0.00011807743658210948,
      "loss": 0.4782,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.7452101707458496,
      "learning_rate": 0.00011754339118825102,
      "loss": 0.4885,
      "step": 1550
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.8291909098625183,
      "learning_rate": 0.00011700934579439253,
      "loss": 0.4997,
      "step": 1560
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.7034304141998291,
      "learning_rate": 0.00011647530040053405,
      "loss": 0.4621,
      "step": 1570
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.9840602874755859,
      "learning_rate": 0.00011594125500667556,
      "loss": 0.5213,
      "step": 1580
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.6626777052879333,
      "learning_rate": 0.0001154072096128171,
      "loss": 0.4737,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.7716477513313293,
      "learning_rate": 0.00011487316421895862,
      "loss": 0.4531,
      "step": 1600
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.8022140860557556,
      "learning_rate": 0.00011433911882510013,
      "loss": 0.4745,
      "step": 1610
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.8857919573783875,
      "learning_rate": 0.00011380507343124168,
      "loss": 0.5797,
      "step": 1620
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.7742284536361694,
      "learning_rate": 0.00011327102803738319,
      "loss": 0.5008,
      "step": 1630
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.6977835893630981,
      "learning_rate": 0.00011273698264352471,
      "loss": 0.4873,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.7885328531265259,
      "learning_rate": 0.00011220293724966622,
      "loss": 0.4518,
      "step": 1650
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.826137900352478,
      "learning_rate": 0.00011166889185580775,
      "loss": 0.4536,
      "step": 1660
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.6795981526374817,
      "learning_rate": 0.00011113484646194928,
      "loss": 0.4447,
      "step": 1670
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.7876362800598145,
      "learning_rate": 0.00011060080106809079,
      "loss": 0.4636,
      "step": 1680
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.7597970962524414,
      "learning_rate": 0.00011006675567423232,
      "loss": 0.458,
      "step": 1690
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.7433220744132996,
      "learning_rate": 0.00010953271028037384,
      "loss": 0.4684,
      "step": 1700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.797484815120697,
      "learning_rate": 0.00010899866488651535,
      "loss": 0.4715,
      "step": 1710
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.6053509712219238,
      "learning_rate": 0.00010846461949265688,
      "loss": 0.4687,
      "step": 1720
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.7750299572944641,
      "learning_rate": 0.00010793057409879841,
      "loss": 0.4901,
      "step": 1730
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.9280434846878052,
      "learning_rate": 0.00010739652870493992,
      "loss": 0.4399,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.6816861629486084,
      "learning_rate": 0.00010686248331108144,
      "loss": 0.4974,
      "step": 1750
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.8060230016708374,
      "learning_rate": 0.00010632843791722298,
      "loss": 0.4555,
      "step": 1760
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.7980890274047852,
      "learning_rate": 0.00010579439252336449,
      "loss": 0.4876,
      "step": 1770
    },
    {
      "epoch": 1.424,
      "grad_norm": 1.0155061483383179,
      "learning_rate": 0.00010526034712950601,
      "loss": 0.4848,
      "step": 1780
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.9424245357513428,
      "learning_rate": 0.00010472630173564752,
      "loss": 0.5032,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.7036858797073364,
      "learning_rate": 0.00010419225634178906,
      "loss": 0.4717,
      "step": 1800
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.7157902717590332,
      "learning_rate": 0.00010365821094793058,
      "loss": 0.4094,
      "step": 1810
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.8420805931091309,
      "learning_rate": 0.00010312416555407209,
      "loss": 0.4934,
      "step": 1820
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.7157149910926819,
      "learning_rate": 0.00010259012016021363,
      "loss": 0.4898,
      "step": 1830
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.7646732330322266,
      "learning_rate": 0.00010205607476635515,
      "loss": 0.4378,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.7863355875015259,
      "learning_rate": 0.00010152202937249666,
      "loss": 0.4845,
      "step": 1850
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.9846226572990417,
      "learning_rate": 0.00010098798397863818,
      "loss": 0.4714,
      "step": 1860
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.6500329375267029,
      "learning_rate": 0.00010045393858477972,
      "loss": 0.4684,
      "step": 1870
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.8616684079170227,
      "learning_rate": 9.991989319092123e-05,
      "loss": 0.4421,
      "step": 1880
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.8296912908554077,
      "learning_rate": 9.938584779706276e-05,
      "loss": 0.4921,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.6722790598869324,
      "learning_rate": 9.885180240320427e-05,
      "loss": 0.4596,
      "step": 1900
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.8386968374252319,
      "learning_rate": 9.831775700934581e-05,
      "loss": 0.4263,
      "step": 1910
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.9082375764846802,
      "learning_rate": 9.778371161548732e-05,
      "loss": 0.4649,
      "step": 1920
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.8048915863037109,
      "learning_rate": 9.724966622162884e-05,
      "loss": 0.4857,
      "step": 1930
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.809592604637146,
      "learning_rate": 9.671562082777038e-05,
      "loss": 0.4592,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.7402387857437134,
      "learning_rate": 9.618157543391188e-05,
      "loss": 0.4487,
      "step": 1950
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.736811637878418,
      "learning_rate": 9.564753004005341e-05,
      "loss": 0.44,
      "step": 1960
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.8943238258361816,
      "learning_rate": 9.511348464619493e-05,
      "loss": 0.4988,
      "step": 1970
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.7996745705604553,
      "learning_rate": 9.457943925233645e-05,
      "loss": 0.464,
      "step": 1980
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.8346501588821411,
      "learning_rate": 9.404539385847798e-05,
      "loss": 0.455,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7759758830070496,
      "learning_rate": 9.35113484646195e-05,
      "loss": 0.4642,
      "step": 2000
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.7813093066215515,
      "learning_rate": 9.297730307076102e-05,
      "loss": 0.4614,
      "step": 2010
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.933975338935852,
      "learning_rate": 9.244325767690254e-05,
      "loss": 0.453,
      "step": 2020
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.9766452312469482,
      "learning_rate": 9.190921228304407e-05,
      "loss": 0.4444,
      "step": 2030
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.8263159394264221,
      "learning_rate": 9.137516688918557e-05,
      "loss": 0.4884,
      "step": 2040
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 1.0442456007003784,
      "learning_rate": 9.084112149532711e-05,
      "loss": 0.4681,
      "step": 2050
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.8120383024215698,
      "learning_rate": 9.030707610146862e-05,
      "loss": 0.4574,
      "step": 2060
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.7792117595672607,
      "learning_rate": 8.977303070761016e-05,
      "loss": 0.4404,
      "step": 2070
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.7033870816230774,
      "learning_rate": 8.923898531375168e-05,
      "loss": 0.4619,
      "step": 2080
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.9480505585670471,
      "learning_rate": 8.870493991989319e-05,
      "loss": 0.4295,
      "step": 2090
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.895381510257721,
      "learning_rate": 8.817089452603472e-05,
      "loss": 0.431,
      "step": 2100
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.8826645612716675,
      "learning_rate": 8.763684913217623e-05,
      "loss": 0.4827,
      "step": 2110
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.6648949980735779,
      "learning_rate": 8.710280373831776e-05,
      "loss": 0.4521,
      "step": 2120
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.8207390308380127,
      "learning_rate": 8.656875834445929e-05,
      "loss": 0.4849,
      "step": 2130
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.8294481039047241,
      "learning_rate": 8.60347129506008e-05,
      "loss": 0.45,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.734450101852417,
      "learning_rate": 8.550066755674232e-05,
      "loss": 0.4573,
      "step": 2150
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.8053204417228699,
      "learning_rate": 8.496662216288385e-05,
      "loss": 0.4808,
      "step": 2160
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.8321717977523804,
      "learning_rate": 8.443257676902537e-05,
      "loss": 0.4359,
      "step": 2170
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.765013575553894,
      "learning_rate": 8.389853137516689e-05,
      "loss": 0.4339,
      "step": 2180
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.8347046971321106,
      "learning_rate": 8.336448598130842e-05,
      "loss": 0.4671,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.8264017105102539,
      "learning_rate": 8.283044058744994e-05,
      "loss": 0.4226,
      "step": 2200
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.7335619926452637,
      "learning_rate": 8.229639519359146e-05,
      "loss": 0.4139,
      "step": 2210
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.8682528734207153,
      "learning_rate": 8.176234979973298e-05,
      "loss": 0.461,
      "step": 2220
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.8296248912811279,
      "learning_rate": 8.12283044058745e-05,
      "loss": 0.4329,
      "step": 2230
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.7642471194267273,
      "learning_rate": 8.069425901201603e-05,
      "loss": 0.4331,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.8247487545013428,
      "learning_rate": 8.016021361815754e-05,
      "loss": 0.4488,
      "step": 2250
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.7850531935691833,
      "learning_rate": 7.962616822429907e-05,
      "loss": 0.4763,
      "step": 2260
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.8253908753395081,
      "learning_rate": 7.90921228304406e-05,
      "loss": 0.5048,
      "step": 2270
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.6989220380783081,
      "learning_rate": 7.85580774365821e-05,
      "loss": 0.4396,
      "step": 2280
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.7969710826873779,
      "learning_rate": 7.802403204272364e-05,
      "loss": 0.4693,
      "step": 2290
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.7764948010444641,
      "learning_rate": 7.748998664886515e-05,
      "loss": 0.4362,
      "step": 2300
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 1.0495058298110962,
      "learning_rate": 7.695594125500669e-05,
      "loss": 0.444,
      "step": 2310
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.8317220211029053,
      "learning_rate": 7.64218958611482e-05,
      "loss": 0.4727,
      "step": 2320
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.9002704620361328,
      "learning_rate": 7.588785046728972e-05,
      "loss": 0.447,
      "step": 2330
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.9322518706321716,
      "learning_rate": 7.535380507343126e-05,
      "loss": 0.4473,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.8854369521141052,
      "learning_rate": 7.481975967957276e-05,
      "loss": 0.4448,
      "step": 2350
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.7585166096687317,
      "learning_rate": 7.428571428571429e-05,
      "loss": 0.4438,
      "step": 2360
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.8139373660087585,
      "learning_rate": 7.375166889185581e-05,
      "loss": 0.4541,
      "step": 2370
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.7104863524436951,
      "learning_rate": 7.321762349799733e-05,
      "loss": 0.4786,
      "step": 2380
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.7689392566680908,
      "learning_rate": 7.268357810413885e-05,
      "loss": 0.428,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.8549288511276245,
      "learning_rate": 7.214953271028038e-05,
      "loss": 0.5223,
      "step": 2400
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.82874596118927,
      "learning_rate": 7.16154873164219e-05,
      "loss": 0.4538,
      "step": 2410
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.8149675726890564,
      "learning_rate": 7.108144192256342e-05,
      "loss": 0.4776,
      "step": 2420
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.7513582706451416,
      "learning_rate": 7.054739652870495e-05,
      "loss": 0.4421,
      "step": 2430
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.8604586124420166,
      "learning_rate": 7.001335113484645e-05,
      "loss": 0.427,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.773207426071167,
      "learning_rate": 6.947930574098799e-05,
      "loss": 0.4794,
      "step": 2450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.956348180770874,
      "learning_rate": 6.894526034712951e-05,
      "loss": 0.4036,
      "step": 2460
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.707415759563446,
      "learning_rate": 6.841121495327104e-05,
      "loss": 0.4355,
      "step": 2470
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.8560668230056763,
      "learning_rate": 6.787716955941256e-05,
      "loss": 0.4729,
      "step": 2480
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.9491798281669617,
      "learning_rate": 6.734312416555407e-05,
      "loss": 0.4069,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6793751120567322,
      "learning_rate": 6.68090787716956e-05,
      "loss": 0.4644,
      "step": 2500
    },
    {
      "epoch": 2.008,
      "grad_norm": 1.0218087434768677,
      "learning_rate": 6.627503337783711e-05,
      "loss": 0.2698,
      "step": 2510
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.8820694088935852,
      "learning_rate": 6.574098798397864e-05,
      "loss": 0.2437,
      "step": 2520
    },
    {
      "epoch": 2.024,
      "grad_norm": 1.0801304578781128,
      "learning_rate": 6.520694259012017e-05,
      "loss": 0.2501,
      "step": 2530
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.8325651288032532,
      "learning_rate": 6.467289719626168e-05,
      "loss": 0.2134,
      "step": 2540
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.7773586511611938,
      "learning_rate": 6.41388518024032e-05,
      "loss": 0.2371,
      "step": 2550
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.8818165063858032,
      "learning_rate": 6.360480640854473e-05,
      "loss": 0.2492,
      "step": 2560
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.9495373964309692,
      "learning_rate": 6.307076101468625e-05,
      "loss": 0.2205,
      "step": 2570
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.5834463834762573,
      "learning_rate": 6.253671562082777e-05,
      "loss": 0.2183,
      "step": 2580
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.9098087549209595,
      "learning_rate": 6.20026702269693e-05,
      "loss": 0.2484,
      "step": 2590
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.962533175945282,
      "learning_rate": 6.146862483311082e-05,
      "loss": 0.2382,
      "step": 2600
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.8339369297027588,
      "learning_rate": 6.093457943925234e-05,
      "loss": 0.2362,
      "step": 2610
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.8987990021705627,
      "learning_rate": 6.040053404539386e-05,
      "loss": 0.3122,
      "step": 2620
    },
    {
      "epoch": 2.104,
      "grad_norm": 0.8657698035240173,
      "learning_rate": 5.986648865153538e-05,
      "loss": 0.2266,
      "step": 2630
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.942462682723999,
      "learning_rate": 5.933244325767691e-05,
      "loss": 0.2514,
      "step": 2640
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.765436589717865,
      "learning_rate": 5.8798397863818424e-05,
      "loss": 0.2213,
      "step": 2650
    },
    {
      "epoch": 2.128,
      "grad_norm": 1.0230604410171509,
      "learning_rate": 5.826435246995995e-05,
      "loss": 0.2223,
      "step": 2660
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.9513777494430542,
      "learning_rate": 5.7730307076101476e-05,
      "loss": 0.2231,
      "step": 2670
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.8865394592285156,
      "learning_rate": 5.719626168224299e-05,
      "loss": 0.2536,
      "step": 2680
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.9304961562156677,
      "learning_rate": 5.6662216288384515e-05,
      "loss": 0.2465,
      "step": 2690
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.9866710901260376,
      "learning_rate": 5.612817089452603e-05,
      "loss": 0.256,
      "step": 2700
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.82715904712677,
      "learning_rate": 5.559412550066756e-05,
      "loss": 0.2343,
      "step": 2710
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.8301978707313538,
      "learning_rate": 5.506008010680909e-05,
      "loss": 0.2471,
      "step": 2720
    },
    {
      "epoch": 2.184,
      "grad_norm": 1.1892435550689697,
      "learning_rate": 5.4526034712950606e-05,
      "loss": 0.2401,
      "step": 2730
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.8795844316482544,
      "learning_rate": 5.399198931909213e-05,
      "loss": 0.2285,
      "step": 2740
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.9457001686096191,
      "learning_rate": 5.3457943925233644e-05,
      "loss": 0.2427,
      "step": 2750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.7792471051216125,
      "learning_rate": 5.2923898531375174e-05,
      "loss": 0.2299,
      "step": 2760
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.8300255537033081,
      "learning_rate": 5.238985313751669e-05,
      "loss": 0.235,
      "step": 2770
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.997377336025238,
      "learning_rate": 5.185580774365821e-05,
      "loss": 0.2281,
      "step": 2780
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.8662635684013367,
      "learning_rate": 5.132176234979974e-05,
      "loss": 0.2409,
      "step": 2790
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.8034549355506897,
      "learning_rate": 5.078771695594126e-05,
      "loss": 0.2341,
      "step": 2800
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.8327623009681702,
      "learning_rate": 5.025367156208278e-05,
      "loss": 0.2448,
      "step": 2810
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.8927593231201172,
      "learning_rate": 4.97196261682243e-05,
      "loss": 0.2494,
      "step": 2820
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.9274275898933411,
      "learning_rate": 4.9185580774365825e-05,
      "loss": 0.2355,
      "step": 2830
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.9515248537063599,
      "learning_rate": 4.865153538050735e-05,
      "loss": 0.2435,
      "step": 2840
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.8001407384872437,
      "learning_rate": 4.8117489986648864e-05,
      "loss": 0.2364,
      "step": 2850
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.871952474117279,
      "learning_rate": 4.758344459279039e-05,
      "loss": 0.2253,
      "step": 2860
    },
    {
      "epoch": 2.296,
      "grad_norm": 1.099822998046875,
      "learning_rate": 4.704939919893191e-05,
      "loss": 0.2355,
      "step": 2870
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.7958500385284424,
      "learning_rate": 4.651535380507344e-05,
      "loss": 0.2846,
      "step": 2880
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.7359010577201843,
      "learning_rate": 4.5981308411214955e-05,
      "loss": 0.2299,
      "step": 2890
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.9847809076309204,
      "learning_rate": 4.544726301735648e-05,
      "loss": 0.222,
      "step": 2900
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.8084623217582703,
      "learning_rate": 4.4913217623498e-05,
      "loss": 0.2349,
      "step": 2910
    },
    {
      "epoch": 2.336,
      "grad_norm": 1.8296152353286743,
      "learning_rate": 4.437917222963952e-05,
      "loss": 0.3178,
      "step": 2920
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.790934145450592,
      "learning_rate": 4.384512683578104e-05,
      "loss": 0.2212,
      "step": 2930
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.7129115462303162,
      "learning_rate": 4.331108144192256e-05,
      "loss": 0.2309,
      "step": 2940
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.9348169565200806,
      "learning_rate": 4.277703604806409e-05,
      "loss": 0.2592,
      "step": 2950
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.8786264061927795,
      "learning_rate": 4.2242990654205613e-05,
      "loss": 0.2338,
      "step": 2960
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.7560269236564636,
      "learning_rate": 4.170894526034713e-05,
      "loss": 0.2311,
      "step": 2970
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.8506557941436768,
      "learning_rate": 4.117489986648865e-05,
      "loss": 0.2479,
      "step": 2980
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.865117073059082,
      "learning_rate": 4.0640854472630175e-05,
      "loss": 0.2606,
      "step": 2990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.991419792175293,
      "learning_rate": 4.01068090787717e-05,
      "loss": 0.2314,
      "step": 3000
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.8353207111358643,
      "learning_rate": 3.957276368491322e-05,
      "loss": 0.241,
      "step": 3010
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.7888765931129456,
      "learning_rate": 3.903871829105474e-05,
      "loss": 0.2206,
      "step": 3020
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.8994254469871521,
      "learning_rate": 3.8504672897196265e-05,
      "loss": 0.2355,
      "step": 3030
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.5798910856246948,
      "learning_rate": 3.797062750333779e-05,
      "loss": 0.2344,
      "step": 3040
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.7775997519493103,
      "learning_rate": 3.7436582109479304e-05,
      "loss": 0.2369,
      "step": 3050
    },
    {
      "epoch": 2.448,
      "grad_norm": 1.0133979320526123,
      "learning_rate": 3.690253671562083e-05,
      "loss": 0.2477,
      "step": 3060
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.8213474750518799,
      "learning_rate": 3.636849132176235e-05,
      "loss": 0.236,
      "step": 3070
    },
    {
      "epoch": 2.464,
      "grad_norm": 1.1705710887908936,
      "learning_rate": 3.583444592790388e-05,
      "loss": 0.237,
      "step": 3080
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.9119954705238342,
      "learning_rate": 3.5300400534045395e-05,
      "loss": 0.2393,
      "step": 3090
    },
    {
      "epoch": 2.48,
      "grad_norm": 1.0109872817993164,
      "learning_rate": 3.476635514018692e-05,
      "loss": 0.236,
      "step": 3100
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.8032986521720886,
      "learning_rate": 3.423230974632844e-05,
      "loss": 0.3111,
      "step": 3110
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.7218526005744934,
      "learning_rate": 3.369826435246996e-05,
      "loss": 0.2193,
      "step": 3120
    },
    {
      "epoch": 2.504,
      "grad_norm": 2.265691041946411,
      "learning_rate": 3.316421895861148e-05,
      "loss": 0.2809,
      "step": 3130
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.758554995059967,
      "learning_rate": 3.263017356475301e-05,
      "loss": 0.245,
      "step": 3140
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.8003398180007935,
      "learning_rate": 3.209612817089453e-05,
      "loss": 0.2547,
      "step": 3150
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.7335474491119385,
      "learning_rate": 3.156208277703605e-05,
      "loss": 0.2226,
      "step": 3160
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.7822250127792358,
      "learning_rate": 3.102803738317757e-05,
      "loss": 0.2272,
      "step": 3170
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.7947984337806702,
      "learning_rate": 3.0493991989319092e-05,
      "loss": 0.2364,
      "step": 3180
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.8146127462387085,
      "learning_rate": 2.9959946595460615e-05,
      "loss": 0.2377,
      "step": 3190
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.9986252784729004,
      "learning_rate": 2.9425901201602134e-05,
      "loss": 0.2589,
      "step": 3200
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.9641366600990295,
      "learning_rate": 2.8891855807743663e-05,
      "loss": 0.2367,
      "step": 3210
    },
    {
      "epoch": 2.576,
      "grad_norm": 1.0022754669189453,
      "learning_rate": 2.8357810413885183e-05,
      "loss": 0.2262,
      "step": 3220
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.8901171684265137,
      "learning_rate": 2.7823765020026705e-05,
      "loss": 0.2334,
      "step": 3230
    },
    {
      "epoch": 2.592,
      "grad_norm": 1.0137847661972046,
      "learning_rate": 2.7289719626168225e-05,
      "loss": 0.2344,
      "step": 3240
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.9124739170074463,
      "learning_rate": 2.6755674232309747e-05,
      "loss": 0.2012,
      "step": 3250
    },
    {
      "epoch": 2.608,
      "grad_norm": 1.0102101564407349,
      "learning_rate": 2.6221628838451267e-05,
      "loss": 0.2291,
      "step": 3260
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.9272817969322205,
      "learning_rate": 2.5687583444592793e-05,
      "loss": 0.2326,
      "step": 3270
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.673435628414154,
      "learning_rate": 2.5153538050734315e-05,
      "loss": 0.2413,
      "step": 3280
    },
    {
      "epoch": 2.632,
      "grad_norm": 1.063462257385254,
      "learning_rate": 2.4619492656875838e-05,
      "loss": 0.2338,
      "step": 3290
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.9292598366737366,
      "learning_rate": 2.4085447263017357e-05,
      "loss": 0.2445,
      "step": 3300
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.7558905482292175,
      "learning_rate": 2.355140186915888e-05,
      "loss": 0.2335,
      "step": 3310
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.7546155452728271,
      "learning_rate": 2.3017356475300403e-05,
      "loss": 0.2316,
      "step": 3320
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.9436349868774414,
      "learning_rate": 2.2483311081441925e-05,
      "loss": 0.2276,
      "step": 3330
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.7559799551963806,
      "learning_rate": 2.1949265687583445e-05,
      "loss": 0.2279,
      "step": 3340
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.8735558390617371,
      "learning_rate": 2.1415220293724967e-05,
      "loss": 0.235,
      "step": 3350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.8577532172203064,
      "learning_rate": 2.088117489986649e-05,
      "loss": 0.2289,
      "step": 3360
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.838179886341095,
      "learning_rate": 2.0347129506008013e-05,
      "loss": 0.221,
      "step": 3370
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.8639366030693054,
      "learning_rate": 1.9813084112149532e-05,
      "loss": 0.2191,
      "step": 3380
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.8702033758163452,
      "learning_rate": 1.9279038718291058e-05,
      "loss": 0.2247,
      "step": 3390
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.9389203190803528,
      "learning_rate": 1.8744993324432577e-05,
      "loss": 0.2246,
      "step": 3400
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.7664129137992859,
      "learning_rate": 1.82109479305741e-05,
      "loss": 0.2224,
      "step": 3410
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.9730261564254761,
      "learning_rate": 1.7676902536715623e-05,
      "loss": 0.2345,
      "step": 3420
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.823901891708374,
      "learning_rate": 1.7142857142857145e-05,
      "loss": 0.1924,
      "step": 3430
    },
    {
      "epoch": 2.752,
      "grad_norm": 1.00844144821167,
      "learning_rate": 1.6608811748998665e-05,
      "loss": 0.2457,
      "step": 3440
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.8118495345115662,
      "learning_rate": 1.607476635514019e-05,
      "loss": 0.2162,
      "step": 3450
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.9375689625740051,
      "learning_rate": 1.554072096128171e-05,
      "loss": 0.2292,
      "step": 3460
    },
    {
      "epoch": 2.776,
      "grad_norm": 1.1014533042907715,
      "learning_rate": 1.500667556742323e-05,
      "loss": 0.2119,
      "step": 3470
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.9388473629951477,
      "learning_rate": 1.4472630173564752e-05,
      "loss": 0.2379,
      "step": 3480
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.9747101664543152,
      "learning_rate": 1.3938584779706276e-05,
      "loss": 0.2325,
      "step": 3490
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.073100209236145,
      "learning_rate": 1.3404539385847797e-05,
      "loss": 0.2178,
      "step": 3500
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.965523898601532,
      "learning_rate": 1.2870493991989318e-05,
      "loss": 0.2575,
      "step": 3510
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.9979627728462219,
      "learning_rate": 1.233644859813084e-05,
      "loss": 0.2243,
      "step": 3520
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.7850544452667236,
      "learning_rate": 1.1802403204272363e-05,
      "loss": 0.2238,
      "step": 3530
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.7812957167625427,
      "learning_rate": 1.1268357810413886e-05,
      "loss": 0.2194,
      "step": 3540
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.7749847769737244,
      "learning_rate": 1.0734312416555407e-05,
      "loss": 0.2322,
      "step": 3550
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.9709525108337402,
      "learning_rate": 1.020026702269693e-05,
      "loss": 0.2511,
      "step": 3560
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.9125186800956726,
      "learning_rate": 9.66622162883845e-06,
      "loss": 0.2136,
      "step": 3570
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.7784188389778137,
      "learning_rate": 9.132176234979973e-06,
      "loss": 0.224,
      "step": 3580
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.8634350895881653,
      "learning_rate": 8.598130841121496e-06,
      "loss": 0.2308,
      "step": 3590
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.8869235515594482,
      "learning_rate": 8.064085447263017e-06,
      "loss": 0.226,
      "step": 3600
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.8399868607521057,
      "learning_rate": 7.53004005340454e-06,
      "loss": 0.2103,
      "step": 3610
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.8319396376609802,
      "learning_rate": 6.9959946595460625e-06,
      "loss": 0.2184,
      "step": 3620
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.8951340913772583,
      "learning_rate": 6.4619492656875834e-06,
      "loss": 0.2388,
      "step": 3630
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.9529419541358948,
      "learning_rate": 5.927903871829106e-06,
      "loss": 0.2206,
      "step": 3640
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.7730991840362549,
      "learning_rate": 5.393858477970628e-06,
      "loss": 0.2277,
      "step": 3650
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.8452253341674805,
      "learning_rate": 4.85981308411215e-06,
      "loss": 0.2417,
      "step": 3660
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.9028562307357788,
      "learning_rate": 4.325767690253672e-06,
      "loss": 0.2219,
      "step": 3670
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.8708975911140442,
      "learning_rate": 3.7917222963951934e-06,
      "loss": 0.216,
      "step": 3680
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.8689525127410889,
      "learning_rate": 3.257676902536716e-06,
      "loss": 0.2309,
      "step": 3690
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.9134402275085449,
      "learning_rate": 2.723631508678238e-06,
      "loss": 0.2381,
      "step": 3700
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.9041199684143066,
      "learning_rate": 2.1895861148197598e-06,
      "loss": 0.2089,
      "step": 3710
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.7799175381660461,
      "learning_rate": 1.6555407209612818e-06,
      "loss": 0.212,
      "step": 3720
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.8812940120697021,
      "learning_rate": 1.1214953271028036e-06,
      "loss": 0.2411,
      "step": 3730
    },
    {
      "epoch": 2.992,
      "grad_norm": 1.065084457397461,
      "learning_rate": 5.874499332443259e-07,
      "loss": 0.2343,
      "step": 3740
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.7969081997871399,
      "learning_rate": 5.34045393858478e-08,
      "loss": 0.2188,
      "step": 3750
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.947607809361183e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
