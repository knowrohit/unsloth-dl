{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3750,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008,
      "grad_norm": 1.0664178133010864,
      "learning_rate": 0.00029967957276368486,
      "loss": 1.367,
      "step": 10
    },
    {
      "epoch": 0.016,
      "grad_norm": 0.6358017325401306,
      "learning_rate": 0.00029887850467289715,
      "loss": 0.8514,
      "step": 20
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.646626353263855,
      "learning_rate": 0.00029807743658210944,
      "loss": 0.7312,
      "step": 30
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.49370867013931274,
      "learning_rate": 0.00029727636849132173,
      "loss": 0.7748,
      "step": 40
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.4324197769165039,
      "learning_rate": 0.000296475300400534,
      "loss": 0.7392,
      "step": 50
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.4806252419948578,
      "learning_rate": 0.0002956742323097463,
      "loss": 0.748,
      "step": 60
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.42798662185668945,
      "learning_rate": 0.0002948731642189586,
      "loss": 0.7397,
      "step": 70
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.36789432168006897,
      "learning_rate": 0.00029407209612817084,
      "loss": 0.6855,
      "step": 80
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.48693153262138367,
      "learning_rate": 0.00029327102803738313,
      "loss": 0.6738,
      "step": 90
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.4748331308364868,
      "learning_rate": 0.0002924699599465954,
      "loss": 0.7114,
      "step": 100
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.45762184262275696,
      "learning_rate": 0.0002916688918558077,
      "loss": 0.751,
      "step": 110
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.4691760241985321,
      "learning_rate": 0.00029086782376502,
      "loss": 0.6874,
      "step": 120
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.448427677154541,
      "learning_rate": 0.0002900667556742323,
      "loss": 0.7325,
      "step": 130
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.5174057483673096,
      "learning_rate": 0.0002892656875834446,
      "loss": 0.6793,
      "step": 140
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.4292404055595398,
      "learning_rate": 0.0002884646194926568,
      "loss": 0.6805,
      "step": 150
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.6246774792671204,
      "learning_rate": 0.0002876635514018691,
      "loss": 0.7104,
      "step": 160
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.4512547254562378,
      "learning_rate": 0.0002868624833110814,
      "loss": 0.7188,
      "step": 170
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.38388195633888245,
      "learning_rate": 0.0002860614152202937,
      "loss": 0.7837,
      "step": 180
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.35742321610450745,
      "learning_rate": 0.000285260347129506,
      "loss": 0.7459,
      "step": 190
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.42411336302757263,
      "learning_rate": 0.0002844592790387183,
      "loss": 0.6938,
      "step": 200
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.5837118029594421,
      "learning_rate": 0.00028365821094793056,
      "loss": 0.7216,
      "step": 210
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.4164617657661438,
      "learning_rate": 0.0002828571428571428,
      "loss": 0.7213,
      "step": 220
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.42659759521484375,
      "learning_rate": 0.0002820560747663551,
      "loss": 0.6798,
      "step": 230
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.42937639355659485,
      "learning_rate": 0.0002812550066755674,
      "loss": 0.705,
      "step": 240
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.41055941581726074,
      "learning_rate": 0.0002804539385847797,
      "loss": 0.7269,
      "step": 250
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.4445059597492218,
      "learning_rate": 0.00027965287049399196,
      "loss": 0.6733,
      "step": 260
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.42740195989608765,
      "learning_rate": 0.00027885180240320426,
      "loss": 0.6944,
      "step": 270
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.3954869210720062,
      "learning_rate": 0.00027805073431241655,
      "loss": 0.7006,
      "step": 280
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.4106060564517975,
      "learning_rate": 0.0002772496662216288,
      "loss": 0.679,
      "step": 290
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.389571875333786,
      "learning_rate": 0.0002764485981308411,
      "loss": 0.7237,
      "step": 300
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.528841495513916,
      "learning_rate": 0.00027564753004005336,
      "loss": 0.7096,
      "step": 310
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.4788671135902405,
      "learning_rate": 0.00027484646194926566,
      "loss": 0.6728,
      "step": 320
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.4410349428653717,
      "learning_rate": 0.00027404539385847795,
      "loss": 0.7217,
      "step": 330
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.46939486265182495,
      "learning_rate": 0.00027324432576769024,
      "loss": 0.7098,
      "step": 340
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.3561685085296631,
      "learning_rate": 0.00027244325767690253,
      "loss": 0.649,
      "step": 350
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.4052933156490326,
      "learning_rate": 0.00027164218958611476,
      "loss": 0.6427,
      "step": 360
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.4280049502849579,
      "learning_rate": 0.00027084112149532705,
      "loss": 0.6657,
      "step": 370
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.37252292037010193,
      "learning_rate": 0.00027004005340453935,
      "loss": 0.7241,
      "step": 380
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.4672071933746338,
      "learning_rate": 0.00026923898531375164,
      "loss": 0.6536,
      "step": 390
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.421575665473938,
      "learning_rate": 0.00026843791722296393,
      "loss": 0.7168,
      "step": 400
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.637895941734314,
      "learning_rate": 0.0002676368491321762,
      "loss": 0.6602,
      "step": 410
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.3861228823661804,
      "learning_rate": 0.0002668357810413885,
      "loss": 0.6679,
      "step": 420
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.3132142126560211,
      "learning_rate": 0.00026603471295060075,
      "loss": 0.7312,
      "step": 430
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.4423181414604187,
      "learning_rate": 0.0002652336448598131,
      "loss": 0.7209,
      "step": 440
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.3655022978782654,
      "learning_rate": 0.0002644325767690253,
      "loss": 0.6532,
      "step": 450
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.5168465971946716,
      "learning_rate": 0.0002636315086782376,
      "loss": 0.6875,
      "step": 460
    },
    {
      "epoch": 0.376,
      "grad_norm": 0.43606695532798767,
      "learning_rate": 0.0002628304405874499,
      "loss": 0.7088,
      "step": 470
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.42343732714653015,
      "learning_rate": 0.0002620293724966622,
      "loss": 0.67,
      "step": 480
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.36013245582580566,
      "learning_rate": 0.0002612283044058745,
      "loss": 0.6279,
      "step": 490
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.38290950655937195,
      "learning_rate": 0.0002604272363150867,
      "loss": 0.6658,
      "step": 500
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.43158894777297974,
      "learning_rate": 0.00025962616822429907,
      "loss": 0.6829,
      "step": 510
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.3620353043079376,
      "learning_rate": 0.0002588251001335113,
      "loss": 0.7011,
      "step": 520
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.4288751184940338,
      "learning_rate": 0.0002580240320427236,
      "loss": 0.6884,
      "step": 530
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.5363581776618958,
      "learning_rate": 0.0002572229639519359,
      "loss": 0.7338,
      "step": 540
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.33623361587524414,
      "learning_rate": 0.0002564218958611482,
      "loss": 0.6482,
      "step": 550
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.5313195586204529,
      "learning_rate": 0.00025562082777036047,
      "loss": 0.7356,
      "step": 560
    },
    {
      "epoch": 0.456,
      "grad_norm": 0.43924278020858765,
      "learning_rate": 0.0002548197596795727,
      "loss": 0.6625,
      "step": 570
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.37318673729896545,
      "learning_rate": 0.00025401869158878505,
      "loss": 0.6682,
      "step": 580
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.41901448369026184,
      "learning_rate": 0.0002532176234979973,
      "loss": 0.6858,
      "step": 590
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6544041633605957,
      "learning_rate": 0.0002524165554072096,
      "loss": 0.6392,
      "step": 600
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.5255812406539917,
      "learning_rate": 0.00025161548731642187,
      "loss": 0.7217,
      "step": 610
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.431069552898407,
      "learning_rate": 0.00025081441922563416,
      "loss": 0.6963,
      "step": 620
    },
    {
      "epoch": 0.504,
      "grad_norm": 0.42490941286087036,
      "learning_rate": 0.00025001335113484645,
      "loss": 0.6868,
      "step": 630
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.5327410697937012,
      "learning_rate": 0.0002492122830440587,
      "loss": 0.6458,
      "step": 640
    },
    {
      "epoch": 0.52,
      "grad_norm": 0.3992440104484558,
      "learning_rate": 0.00024841121495327103,
      "loss": 0.6748,
      "step": 650
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.44409656524658203,
      "learning_rate": 0.00024761014686248327,
      "loss": 0.6919,
      "step": 660
    },
    {
      "epoch": 0.536,
      "grad_norm": 0.4903576374053955,
      "learning_rate": 0.00024680907877169556,
      "loss": 0.683,
      "step": 670
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.43868288397789,
      "learning_rate": 0.00024600801068090785,
      "loss": 0.6839,
      "step": 680
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.33688831329345703,
      "learning_rate": 0.00024520694259012014,
      "loss": 0.6519,
      "step": 690
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.3640865981578827,
      "learning_rate": 0.00024440587449933243,
      "loss": 0.6381,
      "step": 700
    },
    {
      "epoch": 0.568,
      "grad_norm": 0.45395952463150024,
      "learning_rate": 0.0002436048064085447,
      "loss": 0.6974,
      "step": 710
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.3838074207305908,
      "learning_rate": 0.000242803738317757,
      "loss": 0.7061,
      "step": 720
    },
    {
      "epoch": 0.584,
      "grad_norm": 0.3660416305065155,
      "learning_rate": 0.00024200267022696928,
      "loss": 0.648,
      "step": 730
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.4227573871612549,
      "learning_rate": 0.00024120160213618154,
      "loss": 0.6764,
      "step": 740
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.43064215779304504,
      "learning_rate": 0.00024040053404539383,
      "loss": 0.6562,
      "step": 750
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.4300852119922638,
      "learning_rate": 0.00023959946595460612,
      "loss": 0.7006,
      "step": 760
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.37873613834381104,
      "learning_rate": 0.00023879839786381842,
      "loss": 0.626,
      "step": 770
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.4200710654258728,
      "learning_rate": 0.00023799732977303068,
      "loss": 0.6704,
      "step": 780
    },
    {
      "epoch": 0.632,
      "grad_norm": 0.46093371510505676,
      "learning_rate": 0.00023719626168224297,
      "loss": 0.6507,
      "step": 790
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.47231611609458923,
      "learning_rate": 0.00023639519359145526,
      "loss": 0.6946,
      "step": 800
    },
    {
      "epoch": 0.648,
      "grad_norm": 0.47617271542549133,
      "learning_rate": 0.00023559412550066752,
      "loss": 0.7213,
      "step": 810
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.5313185453414917,
      "learning_rate": 0.00023479305740987981,
      "loss": 0.6662,
      "step": 820
    },
    {
      "epoch": 0.664,
      "grad_norm": 0.3855653405189514,
      "learning_rate": 0.0002339919893190921,
      "loss": 0.7042,
      "step": 830
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.4145231544971466,
      "learning_rate": 0.0002331909212283044,
      "loss": 0.6652,
      "step": 840
    },
    {
      "epoch": 0.68,
      "grad_norm": 0.3951829969882965,
      "learning_rate": 0.00023238985313751666,
      "loss": 0.652,
      "step": 850
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.41460177302360535,
      "learning_rate": 0.00023158878504672895,
      "loss": 0.7516,
      "step": 860
    },
    {
      "epoch": 0.696,
      "grad_norm": 0.4954190254211426,
      "learning_rate": 0.00023078771695594124,
      "loss": 0.6546,
      "step": 870
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.5766891241073608,
      "learning_rate": 0.0002299866488651535,
      "loss": 0.6614,
      "step": 880
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.4678553342819214,
      "learning_rate": 0.0002291855807743658,
      "loss": 0.6752,
      "step": 890
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.42604517936706543,
      "learning_rate": 0.0002283845126835781,
      "loss": 0.6535,
      "step": 900
    },
    {
      "epoch": 0.728,
      "grad_norm": 0.4215560257434845,
      "learning_rate": 0.00022758344459279038,
      "loss": 0.6618,
      "step": 910
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.403360515832901,
      "learning_rate": 0.00022678237650200264,
      "loss": 0.6556,
      "step": 920
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.4312784671783447,
      "learning_rate": 0.00022598130841121493,
      "loss": 0.6603,
      "step": 930
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.4621056318283081,
      "learning_rate": 0.00022518024032042722,
      "loss": 0.7025,
      "step": 940
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.5959283113479614,
      "learning_rate": 0.0002243791722296395,
      "loss": 0.6976,
      "step": 950
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.48279696702957153,
      "learning_rate": 0.0002235781041388518,
      "loss": 0.6386,
      "step": 960
    },
    {
      "epoch": 0.776,
      "grad_norm": 0.4542957544326782,
      "learning_rate": 0.00022277703604806407,
      "loss": 0.71,
      "step": 970
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.397460013628006,
      "learning_rate": 0.00022197596795727636,
      "loss": 0.666,
      "step": 980
    },
    {
      "epoch": 0.792,
      "grad_norm": 0.5052411556243896,
      "learning_rate": 0.00022117489986648862,
      "loss": 0.6707,
      "step": 990
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.4604339599609375,
      "learning_rate": 0.0002203738317757009,
      "loss": 0.6277,
      "step": 1000
    },
    {
      "epoch": 0.808,
      "grad_norm": 0.46743547916412354,
      "learning_rate": 0.0002195727636849132,
      "loss": 0.6622,
      "step": 1010
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.46542179584503174,
      "learning_rate": 0.00021877169559412547,
      "loss": 0.6609,
      "step": 1020
    },
    {
      "epoch": 0.824,
      "grad_norm": 0.427717924118042,
      "learning_rate": 0.00021797062750333779,
      "loss": 0.7531,
      "step": 1030
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.4090755581855774,
      "learning_rate": 0.00021716955941255005,
      "loss": 0.6356,
      "step": 1040
    },
    {
      "epoch": 0.84,
      "grad_norm": 0.472194105386734,
      "learning_rate": 0.00021636849132176234,
      "loss": 0.6547,
      "step": 1050
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.44997233152389526,
      "learning_rate": 0.0002155674232309746,
      "loss": 0.6846,
      "step": 1060
    },
    {
      "epoch": 0.856,
      "grad_norm": 0.4505331516265869,
      "learning_rate": 0.0002147663551401869,
      "loss": 0.6911,
      "step": 1070
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.44797685742378235,
      "learning_rate": 0.00021396528704939919,
      "loss": 0.6674,
      "step": 1080
    },
    {
      "epoch": 0.872,
      "grad_norm": 0.42885199189186096,
      "learning_rate": 0.00021316421895861145,
      "loss": 0.6753,
      "step": 1090
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4201923906803131,
      "learning_rate": 0.00021236315086782377,
      "loss": 0.6607,
      "step": 1100
    },
    {
      "epoch": 0.888,
      "grad_norm": 0.4185757339000702,
      "learning_rate": 0.00021156208277703603,
      "loss": 0.6534,
      "step": 1110
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.45626500248908997,
      "learning_rate": 0.00021076101468624832,
      "loss": 0.705,
      "step": 1120
    },
    {
      "epoch": 0.904,
      "grad_norm": 0.36250439286231995,
      "learning_rate": 0.00020995994659546059,
      "loss": 0.6274,
      "step": 1130
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.5294066071510315,
      "learning_rate": 0.00020915887850467288,
      "loss": 0.6177,
      "step": 1140
    },
    {
      "epoch": 0.92,
      "grad_norm": 0.4095829725265503,
      "learning_rate": 0.00020835781041388517,
      "loss": 0.6862,
      "step": 1150
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.42713358998298645,
      "learning_rate": 0.00020755674232309743,
      "loss": 0.6502,
      "step": 1160
    },
    {
      "epoch": 0.936,
      "grad_norm": 0.6510399580001831,
      "learning_rate": 0.00020675567423230975,
      "loss": 0.7213,
      "step": 1170
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.398720383644104,
      "learning_rate": 0.000205954606141522,
      "loss": 0.6652,
      "step": 1180
    },
    {
      "epoch": 0.952,
      "grad_norm": 0.44646450877189636,
      "learning_rate": 0.0002051535380507343,
      "loss": 0.6669,
      "step": 1190
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4763116240501404,
      "learning_rate": 0.00020435246995994657,
      "loss": 0.7086,
      "step": 1200
    },
    {
      "epoch": 0.968,
      "grad_norm": 0.39320921897888184,
      "learning_rate": 0.00020355140186915886,
      "loss": 0.6449,
      "step": 1210
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.38181832432746887,
      "learning_rate": 0.00020275033377837115,
      "loss": 0.648,
      "step": 1220
    },
    {
      "epoch": 0.984,
      "grad_norm": 0.39866191148757935,
      "learning_rate": 0.0002019492656875834,
      "loss": 0.6531,
      "step": 1230
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.5352736115455627,
      "learning_rate": 0.00020114819759679573,
      "loss": 0.7045,
      "step": 1240
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.4552536904811859,
      "learning_rate": 0.000200347129506008,
      "loss": 0.6801,
      "step": 1250
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.6019579172134399,
      "learning_rate": 0.00019954606141522028,
      "loss": 0.587,
      "step": 1260
    },
    {
      "epoch": 1.016,
      "grad_norm": 0.5448479652404785,
      "learning_rate": 0.00019874499332443255,
      "loss": 0.6135,
      "step": 1270
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.4993399381637573,
      "learning_rate": 0.00019794392523364484,
      "loss": 0.5815,
      "step": 1280
    },
    {
      "epoch": 1.032,
      "grad_norm": 0.5666950941085815,
      "learning_rate": 0.00019714285714285713,
      "loss": 0.5881,
      "step": 1290
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.49330493807792664,
      "learning_rate": 0.0001963417890520694,
      "loss": 0.6143,
      "step": 1300
    },
    {
      "epoch": 1.048,
      "grad_norm": 0.4887855350971222,
      "learning_rate": 0.0001955407209612817,
      "loss": 0.621,
      "step": 1310
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.4499867260456085,
      "learning_rate": 0.00019473965287049397,
      "loss": 0.608,
      "step": 1320
    },
    {
      "epoch": 1.064,
      "grad_norm": 0.5797297954559326,
      "learning_rate": 0.00019393858477970627,
      "loss": 0.6168,
      "step": 1330
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.5255410075187683,
      "learning_rate": 0.00019313751668891853,
      "loss": 0.616,
      "step": 1340
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.5999771952629089,
      "learning_rate": 0.00019233644859813082,
      "loss": 0.6098,
      "step": 1350
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.5962619185447693,
      "learning_rate": 0.0001915353805073431,
      "loss": 0.62,
      "step": 1360
    },
    {
      "epoch": 1.096,
      "grad_norm": 0.5709965229034424,
      "learning_rate": 0.00019073431241655537,
      "loss": 0.6224,
      "step": 1370
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.5126732587814331,
      "learning_rate": 0.0001899332443257677,
      "loss": 0.6292,
      "step": 1380
    },
    {
      "epoch": 1.112,
      "grad_norm": 0.5214488506317139,
      "learning_rate": 0.00018913217623497996,
      "loss": 0.5866,
      "step": 1390
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.4985794723033905,
      "learning_rate": 0.00018833110814419222,
      "loss": 0.6215,
      "step": 1400
    },
    {
      "epoch": 1.1280000000000001,
      "grad_norm": 0.6006677746772766,
      "learning_rate": 0.0001875300400534045,
      "loss": 0.6235,
      "step": 1410
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.5327100157737732,
      "learning_rate": 0.0001867289719626168,
      "loss": 0.6431,
      "step": 1420
    },
    {
      "epoch": 1.144,
      "grad_norm": 0.42621761560440063,
      "learning_rate": 0.0001859279038718291,
      "loss": 0.5814,
      "step": 1430
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.4994957149028778,
      "learning_rate": 0.00018512683578104136,
      "loss": 0.625,
      "step": 1440
    },
    {
      "epoch": 1.16,
      "grad_norm": 0.5386245250701904,
      "learning_rate": 0.00018432576769025367,
      "loss": 0.6237,
      "step": 1450
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.5470845103263855,
      "learning_rate": 0.00018352469959946594,
      "loss": 0.5579,
      "step": 1460
    },
    {
      "epoch": 1.176,
      "grad_norm": 0.4912315905094147,
      "learning_rate": 0.0001827236315086782,
      "loss": 0.6168,
      "step": 1470
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.5748586654663086,
      "learning_rate": 0.00018192256341789052,
      "loss": 0.6258,
      "step": 1480
    },
    {
      "epoch": 1.192,
      "grad_norm": 0.5704542398452759,
      "learning_rate": 0.00018112149532710278,
      "loss": 0.6261,
      "step": 1490
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.7259760499000549,
      "learning_rate": 0.00018032042723631507,
      "loss": 0.5681,
      "step": 1500
    },
    {
      "epoch": 1.208,
      "grad_norm": 0.6417842507362366,
      "learning_rate": 0.00017951935914552734,
      "loss": 0.6103,
      "step": 1510
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.685028612613678,
      "learning_rate": 0.00017871829105473965,
      "loss": 0.6419,
      "step": 1520
    },
    {
      "epoch": 1.224,
      "grad_norm": 0.5971639156341553,
      "learning_rate": 0.00017791722296395192,
      "loss": 0.6118,
      "step": 1530
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.6239901781082153,
      "learning_rate": 0.00017711615487316418,
      "loss": 0.6218,
      "step": 1540
    },
    {
      "epoch": 1.24,
      "grad_norm": 0.4870157837867737,
      "learning_rate": 0.0001763150867823765,
      "loss": 0.6247,
      "step": 1550
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.5408033728599548,
      "learning_rate": 0.00017551401869158876,
      "loss": 0.6276,
      "step": 1560
    },
    {
      "epoch": 1.256,
      "grad_norm": 0.5542020201683044,
      "learning_rate": 0.00017471295060080105,
      "loss": 0.5906,
      "step": 1570
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.9762634634971619,
      "learning_rate": 0.00017391188251001332,
      "loss": 0.6007,
      "step": 1580
    },
    {
      "epoch": 1.272,
      "grad_norm": 0.5118488073348999,
      "learning_rate": 0.00017311081441922564,
      "loss": 0.6229,
      "step": 1590
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5119404792785645,
      "learning_rate": 0.0001723097463284379,
      "loss": 0.6079,
      "step": 1600
    },
    {
      "epoch": 1.288,
      "grad_norm": 0.5702282786369324,
      "learning_rate": 0.00017150867823765016,
      "loss": 0.6145,
      "step": 1610
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.7068786025047302,
      "learning_rate": 0.00017070761014686248,
      "loss": 0.7047,
      "step": 1620
    },
    {
      "epoch": 1.304,
      "grad_norm": 0.6433933973312378,
      "learning_rate": 0.00016990654205607475,
      "loss": 0.6307,
      "step": 1630
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.5260803699493408,
      "learning_rate": 0.00016910547396528704,
      "loss": 0.6194,
      "step": 1640
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.6009340882301331,
      "learning_rate": 0.0001683044058744993,
      "loss": 0.5918,
      "step": 1650
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.6431213617324829,
      "learning_rate": 0.00016750333778371162,
      "loss": 0.5898,
      "step": 1660
    },
    {
      "epoch": 1.336,
      "grad_norm": 0.5377463102340698,
      "learning_rate": 0.00016670226969292388,
      "loss": 0.5754,
      "step": 1670
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.7032901644706726,
      "learning_rate": 0.00016590120160213614,
      "loss": 0.6154,
      "step": 1680
    },
    {
      "epoch": 1.3519999999999999,
      "grad_norm": 0.5189709067344666,
      "learning_rate": 0.00016510013351134846,
      "loss": 0.6204,
      "step": 1690
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.57259202003479,
      "learning_rate": 0.00016429906542056073,
      "loss": 0.6104,
      "step": 1700
    },
    {
      "epoch": 1.3679999999999999,
      "grad_norm": 0.5197710394859314,
      "learning_rate": 0.00016349799732977302,
      "loss": 0.613,
      "step": 1710
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.5475637316703796,
      "learning_rate": 0.00016269692923898528,
      "loss": 0.595,
      "step": 1720
    },
    {
      "epoch": 1.384,
      "grad_norm": 0.5983728766441345,
      "learning_rate": 0.0001618958611481976,
      "loss": 0.6158,
      "step": 1730
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.5865286588668823,
      "learning_rate": 0.00016109479305740986,
      "loss": 0.5668,
      "step": 1740
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.5324010848999023,
      "learning_rate": 0.00016029372496662213,
      "loss": 0.649,
      "step": 1750
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.5950350761413574,
      "learning_rate": 0.00015949265687583444,
      "loss": 0.5889,
      "step": 1760
    },
    {
      "epoch": 1.416,
      "grad_norm": 0.5946918725967407,
      "learning_rate": 0.0001586915887850467,
      "loss": 0.6108,
      "step": 1770
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.6919333338737488,
      "learning_rate": 0.000157890520694259,
      "loss": 0.6087,
      "step": 1780
    },
    {
      "epoch": 1.432,
      "grad_norm": 0.6396727561950684,
      "learning_rate": 0.00015708945260347126,
      "loss": 0.6588,
      "step": 1790
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5037801861763,
      "learning_rate": 0.00015628838451268358,
      "loss": 0.6192,
      "step": 1800
    },
    {
      "epoch": 1.448,
      "grad_norm": 0.4718042016029358,
      "learning_rate": 0.00015548731642189584,
      "loss": 0.531,
      "step": 1810
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.5957028269767761,
      "learning_rate": 0.0001546862483311081,
      "loss": 0.6236,
      "step": 1820
    },
    {
      "epoch": 1.464,
      "grad_norm": 0.48810285329818726,
      "learning_rate": 0.00015388518024032043,
      "loss": 0.6368,
      "step": 1830
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.552386999130249,
      "learning_rate": 0.0001530841121495327,
      "loss": 0.5784,
      "step": 1840
    },
    {
      "epoch": 1.48,
      "grad_norm": 0.565534234046936,
      "learning_rate": 0.00015228304405874498,
      "loss": 0.6666,
      "step": 1850
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.6387168169021606,
      "learning_rate": 0.00015148197596795724,
      "loss": 0.6035,
      "step": 1860
    },
    {
      "epoch": 1.496,
      "grad_norm": 0.490950345993042,
      "learning_rate": 0.00015068090787716956,
      "loss": 0.5986,
      "step": 1870
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.6181067824363708,
      "learning_rate": 0.00014987983978638183,
      "loss": 0.5849,
      "step": 1880
    },
    {
      "epoch": 1.512,
      "grad_norm": 0.5898327827453613,
      "learning_rate": 0.00014907877169559412,
      "loss": 0.6354,
      "step": 1890
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5303206443786621,
      "learning_rate": 0.00014827770360480638,
      "loss": 0.5897,
      "step": 1900
    },
    {
      "epoch": 1.528,
      "grad_norm": 0.610961377620697,
      "learning_rate": 0.00014747663551401867,
      "loss": 0.5757,
      "step": 1910
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.6611366868019104,
      "learning_rate": 0.00014667556742323096,
      "loss": 0.5978,
      "step": 1920
    },
    {
      "epoch": 1.544,
      "grad_norm": 0.49454277753829956,
      "learning_rate": 0.00014587449933244325,
      "loss": 0.6217,
      "step": 1930
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.5148500800132751,
      "learning_rate": 0.00014507343124165554,
      "loss": 0.5993,
      "step": 1940
    },
    {
      "epoch": 1.56,
      "grad_norm": 0.5782924890518188,
      "learning_rate": 0.0001442723631508678,
      "loss": 0.5792,
      "step": 1950
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.49222004413604736,
      "learning_rate": 0.0001434712950600801,
      "loss": 0.5643,
      "step": 1960
    },
    {
      "epoch": 1.576,
      "grad_norm": 0.6720541715621948,
      "learning_rate": 0.00014267022696929236,
      "loss": 0.634,
      "step": 1970
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.5267409682273865,
      "learning_rate": 0.00014186915887850465,
      "loss": 0.611,
      "step": 1980
    },
    {
      "epoch": 1.592,
      "grad_norm": 0.6686022877693176,
      "learning_rate": 0.00014106809078771694,
      "loss": 0.6128,
      "step": 1990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.6260712146759033,
      "learning_rate": 0.00014026702269692923,
      "loss": 0.5896,
      "step": 2000
    },
    {
      "epoch": 1.608,
      "grad_norm": 0.544375479221344,
      "learning_rate": 0.00013946595460614152,
      "loss": 0.6025,
      "step": 2010
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.6234077215194702,
      "learning_rate": 0.0001386648865153538,
      "loss": 0.5925,
      "step": 2020
    },
    {
      "epoch": 1.624,
      "grad_norm": 0.7243793606758118,
      "learning_rate": 0.00013786381842456608,
      "loss": 0.5948,
      "step": 2030
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.6101207733154297,
      "learning_rate": 0.00013706275033377834,
      "loss": 0.6246,
      "step": 2040
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.645660936832428,
      "learning_rate": 0.00013626168224299063,
      "loss": 0.5899,
      "step": 2050
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.5597946047782898,
      "learning_rate": 0.00013546061415220292,
      "loss": 0.5887,
      "step": 2060
    },
    {
      "epoch": 1.6560000000000001,
      "grad_norm": 0.5348720550537109,
      "learning_rate": 0.00013465954606141521,
      "loss": 0.5839,
      "step": 2070
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.4296460747718811,
      "learning_rate": 0.0001338584779706275,
      "loss": 0.6028,
      "step": 2080
    },
    {
      "epoch": 1.6720000000000002,
      "grad_norm": 0.6447292566299438,
      "learning_rate": 0.00013305740987983977,
      "loss": 0.5568,
      "step": 2090
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.643632173538208,
      "learning_rate": 0.00013225634178905206,
      "loss": 0.5574,
      "step": 2100
    },
    {
      "epoch": 1.688,
      "grad_norm": 0.5357385873794556,
      "learning_rate": 0.00013145527369826432,
      "loss": 0.63,
      "step": 2110
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.5264589190483093,
      "learning_rate": 0.00013065420560747661,
      "loss": 0.5782,
      "step": 2120
    },
    {
      "epoch": 1.704,
      "grad_norm": 0.6196046471595764,
      "learning_rate": 0.0001298531375166889,
      "loss": 0.6202,
      "step": 2130
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.5569724440574646,
      "learning_rate": 0.0001290520694259012,
      "loss": 0.6007,
      "step": 2140
    },
    {
      "epoch": 1.72,
      "grad_norm": 0.6427621841430664,
      "learning_rate": 0.0001282510013351135,
      "loss": 0.5887,
      "step": 2150
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.5710312724113464,
      "learning_rate": 0.00012744993324432575,
      "loss": 0.6314,
      "step": 2160
    },
    {
      "epoch": 1.736,
      "grad_norm": 0.5537863373756409,
      "learning_rate": 0.00012664886515353804,
      "loss": 0.6046,
      "step": 2170
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.5447800755500793,
      "learning_rate": 0.0001258477970627503,
      "loss": 0.5602,
      "step": 2180
    },
    {
      "epoch": 1.752,
      "grad_norm": 0.5234361886978149,
      "learning_rate": 0.0001250467289719626,
      "loss": 0.6039,
      "step": 2190
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.6026096940040588,
      "learning_rate": 0.00012424566088117489,
      "loss": 0.5457,
      "step": 2200
    },
    {
      "epoch": 1.768,
      "grad_norm": 0.7028385400772095,
      "learning_rate": 0.00012344459279038718,
      "loss": 0.5738,
      "step": 2210
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.7732031941413879,
      "learning_rate": 0.00012264352469959947,
      "loss": 0.5979,
      "step": 2220
    },
    {
      "epoch": 1.784,
      "grad_norm": 0.5591374635696411,
      "learning_rate": 0.00012184245660881173,
      "loss": 0.5809,
      "step": 2230
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.518516480922699,
      "learning_rate": 0.00012104138851802402,
      "loss": 0.5804,
      "step": 2240
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6121537685394287,
      "learning_rate": 0.0001202403204272363,
      "loss": 0.595,
      "step": 2250
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.6199113130569458,
      "learning_rate": 0.00011943925233644859,
      "loss": 0.6239,
      "step": 2260
    },
    {
      "epoch": 1.8159999999999998,
      "grad_norm": 0.6239258050918579,
      "learning_rate": 0.00011863818424566088,
      "loss": 0.6465,
      "step": 2270
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.5320285558700562,
      "learning_rate": 0.00011783711615487314,
      "loss": 0.5707,
      "step": 2280
    },
    {
      "epoch": 1.8319999999999999,
      "grad_norm": 0.7299523949623108,
      "learning_rate": 0.00011703604806408544,
      "loss": 0.5865,
      "step": 2290
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.6807171702384949,
      "learning_rate": 0.00011623497997329771,
      "loss": 0.5893,
      "step": 2300
    },
    {
      "epoch": 1.8479999999999999,
      "grad_norm": 0.6805737018585205,
      "learning_rate": 0.00011543391188251,
      "loss": 0.5865,
      "step": 2310
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.6637485027313232,
      "learning_rate": 0.00011463284379172228,
      "loss": 0.6277,
      "step": 2320
    },
    {
      "epoch": 1.8639999999999999,
      "grad_norm": 0.6208195090293884,
      "learning_rate": 0.00011383177570093457,
      "loss": 0.5883,
      "step": 2330
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.8510005474090576,
      "learning_rate": 0.00011303070761014686,
      "loss": 0.6033,
      "step": 2340
    },
    {
      "epoch": 1.88,
      "grad_norm": 0.6538590788841248,
      "learning_rate": 0.00011222963951935913,
      "loss": 0.6046,
      "step": 2350
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.5453059077262878,
      "learning_rate": 0.00011142857142857142,
      "loss": 0.5941,
      "step": 2360
    },
    {
      "epoch": 1.896,
      "grad_norm": 0.6408737897872925,
      "learning_rate": 0.0001106275033377837,
      "loss": 0.6036,
      "step": 2370
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.6181091666221619,
      "learning_rate": 0.00010982643524699598,
      "loss": 0.6213,
      "step": 2380
    },
    {
      "epoch": 1.912,
      "grad_norm": 0.6022133231163025,
      "learning_rate": 0.00010902536715620828,
      "loss": 0.5819,
      "step": 2390
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.6035653352737427,
      "learning_rate": 0.00010822429906542055,
      "loss": 0.6746,
      "step": 2400
    },
    {
      "epoch": 1.928,
      "grad_norm": 0.6609212160110474,
      "learning_rate": 0.00010742323097463284,
      "loss": 0.6073,
      "step": 2410
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.5805059671401978,
      "learning_rate": 0.00010662216288384511,
      "loss": 0.6293,
      "step": 2420
    },
    {
      "epoch": 1.944,
      "grad_norm": 0.5680200457572937,
      "learning_rate": 0.0001058210947930574,
      "loss": 0.6095,
      "step": 2430
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.631304144859314,
      "learning_rate": 0.00010502002670226968,
      "loss": 0.5725,
      "step": 2440
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.6352245807647705,
      "learning_rate": 0.00010421895861148197,
      "loss": 0.6511,
      "step": 2450
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.7972691655158997,
      "learning_rate": 0.00010341789052069426,
      "loss": 0.5568,
      "step": 2460
    },
    {
      "epoch": 1.976,
      "grad_norm": 0.5883488655090332,
      "learning_rate": 0.00010261682242990653,
      "loss": 0.5816,
      "step": 2470
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.6998715996742249,
      "learning_rate": 0.00010181575433911882,
      "loss": 0.6065,
      "step": 2480
    },
    {
      "epoch": 1.992,
      "grad_norm": 0.6550229787826538,
      "learning_rate": 0.00010101468624833109,
      "loss": 0.5798,
      "step": 2490
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.5449883937835693,
      "learning_rate": 0.00010021361815754338,
      "loss": 0.6238,
      "step": 2500
    },
    {
      "epoch": 2.008,
      "grad_norm": 0.6331412196159363,
      "learning_rate": 9.941255006675566e-05,
      "loss": 0.5491,
      "step": 2510
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.7197269797325134,
      "learning_rate": 9.861148197596795e-05,
      "loss": 0.5068,
      "step": 2520
    },
    {
      "epoch": 2.024,
      "grad_norm": 0.7153077125549316,
      "learning_rate": 9.781041388518024e-05,
      "loss": 0.5377,
      "step": 2530
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.6418758630752563,
      "learning_rate": 9.700934579439252e-05,
      "loss": 0.4978,
      "step": 2540
    },
    {
      "epoch": 2.04,
      "grad_norm": 0.5937068462371826,
      "learning_rate": 9.62082777036048e-05,
      "loss": 0.5195,
      "step": 2550
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.6036004424095154,
      "learning_rate": 9.540720961281707e-05,
      "loss": 0.5338,
      "step": 2560
    },
    {
      "epoch": 2.056,
      "grad_norm": 0.7941749095916748,
      "learning_rate": 9.460614152202936e-05,
      "loss": 0.5127,
      "step": 2570
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.6301530003547668,
      "learning_rate": 9.380507343124164e-05,
      "loss": 0.4807,
      "step": 2580
    },
    {
      "epoch": 2.072,
      "grad_norm": 0.6318613290786743,
      "learning_rate": 9.300400534045393e-05,
      "loss": 0.5351,
      "step": 2590
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.7650827169418335,
      "learning_rate": 9.220293724966622e-05,
      "loss": 0.5169,
      "step": 2600
    },
    {
      "epoch": 2.088,
      "grad_norm": 0.6648642420768738,
      "learning_rate": 9.14018691588785e-05,
      "loss": 0.5348,
      "step": 2610
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.6260592341423035,
      "learning_rate": 9.060080106809079e-05,
      "loss": 0.6152,
      "step": 2620
    },
    {
      "epoch": 2.104,
      "grad_norm": 1.257537603378296,
      "learning_rate": 8.979973297730305e-05,
      "loss": 0.5058,
      "step": 2630
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.6939206123352051,
      "learning_rate": 8.899866488651534e-05,
      "loss": 0.5173,
      "step": 2640
    },
    {
      "epoch": 2.12,
      "grad_norm": 0.6457610726356506,
      "learning_rate": 8.819759679572762e-05,
      "loss": 0.4889,
      "step": 2650
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.8212156295776367,
      "learning_rate": 8.739652870493991e-05,
      "loss": 0.5062,
      "step": 2660
    },
    {
      "epoch": 2.136,
      "grad_norm": 0.7184250950813293,
      "learning_rate": 8.65954606141522e-05,
      "loss": 0.5151,
      "step": 2670
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.7728591561317444,
      "learning_rate": 8.579439252336448e-05,
      "loss": 0.5526,
      "step": 2680
    },
    {
      "epoch": 2.152,
      "grad_norm": 0.6594691276550293,
      "learning_rate": 8.499332443257677e-05,
      "loss": 0.5679,
      "step": 2690
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.8911789059638977,
      "learning_rate": 8.419225634178903e-05,
      "loss": 0.532,
      "step": 2700
    },
    {
      "epoch": 2.168,
      "grad_norm": 0.7043198347091675,
      "learning_rate": 8.339118825100132e-05,
      "loss": 0.5194,
      "step": 2710
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.6571061015129089,
      "learning_rate": 8.259012016021361e-05,
      "loss": 0.5412,
      "step": 2720
    },
    {
      "epoch": 2.184,
      "grad_norm": 0.7715761661529541,
      "learning_rate": 8.178905206942589e-05,
      "loss": 0.5339,
      "step": 2730
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.7271496653556824,
      "learning_rate": 8.098798397863818e-05,
      "loss": 0.529,
      "step": 2740
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.7036327719688416,
      "learning_rate": 8.018691588785046e-05,
      "loss": 0.5117,
      "step": 2750
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.6466646194458008,
      "learning_rate": 7.938584779706275e-05,
      "loss": 0.5107,
      "step": 2760
    },
    {
      "epoch": 2.216,
      "grad_norm": 0.5693932771682739,
      "learning_rate": 7.858477970627501e-05,
      "loss": 0.5023,
      "step": 2770
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.7402694225311279,
      "learning_rate": 7.77837116154873e-05,
      "loss": 0.4968,
      "step": 2780
    },
    {
      "epoch": 2.232,
      "grad_norm": 0.893179714679718,
      "learning_rate": 7.69826435246996e-05,
      "loss": 0.5756,
      "step": 2790
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.7548271417617798,
      "learning_rate": 7.618157543391187e-05,
      "loss": 0.5343,
      "step": 2800
    },
    {
      "epoch": 2.248,
      "grad_norm": 0.8506616353988647,
      "learning_rate": 7.538050734312416e-05,
      "loss": 0.5189,
      "step": 2810
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.9220839738845825,
      "learning_rate": 7.457943925233644e-05,
      "loss": 0.5433,
      "step": 2820
    },
    {
      "epoch": 2.2640000000000002,
      "grad_norm": 0.735271692276001,
      "learning_rate": 7.377837116154873e-05,
      "loss": 0.5482,
      "step": 2830
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.6489080786705017,
      "learning_rate": 7.297730307076101e-05,
      "loss": 0.5351,
      "step": 2840
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 0.678471028804779,
      "learning_rate": 7.217623497997329e-05,
      "loss": 0.5078,
      "step": 2850
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.7020438313484192,
      "learning_rate": 7.137516688918558e-05,
      "loss": 0.498,
      "step": 2860
    },
    {
      "epoch": 2.296,
      "grad_norm": 0.8154457211494446,
      "learning_rate": 7.057409879839785e-05,
      "loss": 0.513,
      "step": 2870
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.6892462372779846,
      "learning_rate": 6.977303070761014e-05,
      "loss": 0.5682,
      "step": 2880
    },
    {
      "epoch": 2.312,
      "grad_norm": 0.6395776271820068,
      "learning_rate": 6.897196261682242e-05,
      "loss": 0.527,
      "step": 2890
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.7189108729362488,
      "learning_rate": 6.817089452603471e-05,
      "loss": 0.5048,
      "step": 2900
    },
    {
      "epoch": 2.328,
      "grad_norm": 0.6977699398994446,
      "learning_rate": 6.736982643524699e-05,
      "loss": 0.5059,
      "step": 2910
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.8925624489784241,
      "learning_rate": 6.656875834445927e-05,
      "loss": 0.6503,
      "step": 2920
    },
    {
      "epoch": 2.344,
      "grad_norm": 0.7536835670471191,
      "learning_rate": 6.576769025367156e-05,
      "loss": 0.5145,
      "step": 2930
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.7400233745574951,
      "learning_rate": 6.496662216288384e-05,
      "loss": 0.519,
      "step": 2940
    },
    {
      "epoch": 2.36,
      "grad_norm": 0.7117723822593689,
      "learning_rate": 6.416555407209613e-05,
      "loss": 0.5698,
      "step": 2950
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.7273447513580322,
      "learning_rate": 6.33644859813084e-05,
      "loss": 0.5156,
      "step": 2960
    },
    {
      "epoch": 2.376,
      "grad_norm": 0.7239724397659302,
      "learning_rate": 6.25634178905207e-05,
      "loss": 0.5406,
      "step": 2970
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.8335233330726624,
      "learning_rate": 6.176234979973297e-05,
      "loss": 0.5607,
      "step": 2980
    },
    {
      "epoch": 2.392,
      "grad_norm": 0.8475105166435242,
      "learning_rate": 6.0961281708945255e-05,
      "loss": 0.5845,
      "step": 2990
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.605859637260437,
      "learning_rate": 6.016021361815753e-05,
      "loss": 0.5239,
      "step": 3000
    },
    {
      "epoch": 2.408,
      "grad_norm": 0.5719926953315735,
      "learning_rate": 5.935914552736982e-05,
      "loss": 0.5328,
      "step": 3010
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.830610454082489,
      "learning_rate": 5.855807743658211e-05,
      "loss": 0.4994,
      "step": 3020
    },
    {
      "epoch": 2.424,
      "grad_norm": 0.9959489107131958,
      "learning_rate": 5.775700934579439e-05,
      "loss": 0.5362,
      "step": 3030
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.9907382726669312,
      "learning_rate": 5.695594125500667e-05,
      "loss": 0.5237,
      "step": 3040
    },
    {
      "epoch": 2.44,
      "grad_norm": 0.6636869311332703,
      "learning_rate": 5.615487316421895e-05,
      "loss": 0.5376,
      "step": 3050
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.8774075508117676,
      "learning_rate": 5.5353805073431237e-05,
      "loss": 0.5428,
      "step": 3060
    },
    {
      "epoch": 2.456,
      "grad_norm": 0.6184388995170593,
      "learning_rate": 5.4552736982643514e-05,
      "loss": 0.5093,
      "step": 3070
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.6417416930198669,
      "learning_rate": 5.3751668891855805e-05,
      "loss": 0.5111,
      "step": 3080
    },
    {
      "epoch": 2.472,
      "grad_norm": 0.7307129502296448,
      "learning_rate": 5.295060080106809e-05,
      "loss": 0.527,
      "step": 3090
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.8264927864074707,
      "learning_rate": 5.214953271028037e-05,
      "loss": 0.5524,
      "step": 3100
    },
    {
      "epoch": 2.488,
      "grad_norm": 0.6469150185585022,
      "learning_rate": 5.134846461949265e-05,
      "loss": 0.587,
      "step": 3110
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.6010128855705261,
      "learning_rate": 5.0547396528704934e-05,
      "loss": 0.5083,
      "step": 3120
    },
    {
      "epoch": 2.504,
      "grad_norm": 2.532951831817627,
      "learning_rate": 4.974632843791722e-05,
      "loss": 0.5303,
      "step": 3130
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.6858248710632324,
      "learning_rate": 4.894526034712951e-05,
      "loss": 0.5415,
      "step": 3140
    },
    {
      "epoch": 2.52,
      "grad_norm": 0.6782898306846619,
      "learning_rate": 4.8144192256341786e-05,
      "loss": 0.5367,
      "step": 3150
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.9275664687156677,
      "learning_rate": 4.734312416555407e-05,
      "loss": 0.509,
      "step": 3160
    },
    {
      "epoch": 2.536,
      "grad_norm": 0.9515559673309326,
      "learning_rate": 4.6542056074766354e-05,
      "loss": 0.5398,
      "step": 3170
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.7026750445365906,
      "learning_rate": 4.574098798397863e-05,
      "loss": 0.5339,
      "step": 3180
    },
    {
      "epoch": 2.552,
      "grad_norm": 0.7176198959350586,
      "learning_rate": 4.4939919893190915e-05,
      "loss": 0.531,
      "step": 3190
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.761997640132904,
      "learning_rate": 4.41388518024032e-05,
      "loss": 0.602,
      "step": 3200
    },
    {
      "epoch": 2.568,
      "grad_norm": 0.8510185480117798,
      "learning_rate": 4.333778371161549e-05,
      "loss": 0.5461,
      "step": 3210
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.8210608959197998,
      "learning_rate": 4.253671562082777e-05,
      "loss": 0.5357,
      "step": 3220
    },
    {
      "epoch": 2.584,
      "grad_norm": 0.7641671895980835,
      "learning_rate": 4.173564753004005e-05,
      "loss": 0.515,
      "step": 3230
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.6598670482635498,
      "learning_rate": 4.0934579439252335e-05,
      "loss": 0.5123,
      "step": 3240
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.7852305769920349,
      "learning_rate": 4.013351134846461e-05,
      "loss": 0.4892,
      "step": 3250
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.8816962242126465,
      "learning_rate": 3.9332443257676896e-05,
      "loss": 0.5108,
      "step": 3260
    },
    {
      "epoch": 2.616,
      "grad_norm": 0.6597838401794434,
      "learning_rate": 3.853137516688919e-05,
      "loss": 0.5282,
      "step": 3270
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.6777027249336243,
      "learning_rate": 3.773030707610147e-05,
      "loss": 0.538,
      "step": 3280
    },
    {
      "epoch": 2.632,
      "grad_norm": 0.7514663338661194,
      "learning_rate": 3.692923898531375e-05,
      "loss": 0.5298,
      "step": 3290
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7183389663696289,
      "learning_rate": 3.612817089452603e-05,
      "loss": 0.5388,
      "step": 3300
    },
    {
      "epoch": 2.648,
      "grad_norm": 0.6596296429634094,
      "learning_rate": 3.5327102803738316e-05,
      "loss": 0.516,
      "step": 3310
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.6627545952796936,
      "learning_rate": 3.45260347129506e-05,
      "loss": 0.4965,
      "step": 3320
    },
    {
      "epoch": 2.664,
      "grad_norm": 0.6924615502357483,
      "learning_rate": 3.3724966622162885e-05,
      "loss": 0.5324,
      "step": 3330
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.818245530128479,
      "learning_rate": 3.292389853137516e-05,
      "loss": 0.5332,
      "step": 3340
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.7172470092773438,
      "learning_rate": 3.2122830440587446e-05,
      "loss": 0.5356,
      "step": 3350
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.6750932931900024,
      "learning_rate": 3.132176234979973e-05,
      "loss": 0.5268,
      "step": 3360
    },
    {
      "epoch": 2.6959999999999997,
      "grad_norm": 0.7584086060523987,
      "learning_rate": 3.0520694259012014e-05,
      "loss": 0.5428,
      "step": 3370
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.7712473273277283,
      "learning_rate": 2.9719626168224294e-05,
      "loss": 0.5036,
      "step": 3380
    },
    {
      "epoch": 2.7119999999999997,
      "grad_norm": 0.7932149171829224,
      "learning_rate": 2.8918558077436582e-05,
      "loss": 0.5127,
      "step": 3390
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.7938680052757263,
      "learning_rate": 2.8117489986648862e-05,
      "loss": 0.513,
      "step": 3400
    },
    {
      "epoch": 2.7279999999999998,
      "grad_norm": 0.7890152931213379,
      "learning_rate": 2.7316421895861143e-05,
      "loss": 0.531,
      "step": 3410
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.9299290180206299,
      "learning_rate": 2.651535380507343e-05,
      "loss": 0.5505,
      "step": 3420
    },
    {
      "epoch": 2.7439999999999998,
      "grad_norm": 0.7943146824836731,
      "learning_rate": 2.571428571428571e-05,
      "loss": 0.4506,
      "step": 3430
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.6853875517845154,
      "learning_rate": 2.4913217623497995e-05,
      "loss": 0.5438,
      "step": 3440
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.6580524444580078,
      "learning_rate": 2.411214953271028e-05,
      "loss": 0.4827,
      "step": 3450
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.8446251749992371,
      "learning_rate": 2.3311081441922563e-05,
      "loss": 0.527,
      "step": 3460
    },
    {
      "epoch": 2.776,
      "grad_norm": 0.8331709504127502,
      "learning_rate": 2.2510013351134844e-05,
      "loss": 0.5075,
      "step": 3470
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.8879935145378113,
      "learning_rate": 2.1708945260347124e-05,
      "loss": 0.5493,
      "step": 3480
    },
    {
      "epoch": 2.792,
      "grad_norm": 0.8803877234458923,
      "learning_rate": 2.0907877169559412e-05,
      "loss": 0.5363,
      "step": 3490
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.7033541798591614,
      "learning_rate": 2.0106809078771692e-05,
      "loss": 0.5086,
      "step": 3500
    },
    {
      "epoch": 2.808,
      "grad_norm": 0.7510771751403809,
      "learning_rate": 1.9305740987983976e-05,
      "loss": 0.5616,
      "step": 3510
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.700339138507843,
      "learning_rate": 1.850467289719626e-05,
      "loss": 0.5064,
      "step": 3520
    },
    {
      "epoch": 2.824,
      "grad_norm": 0.5879712104797363,
      "learning_rate": 1.7703604806408544e-05,
      "loss": 0.5067,
      "step": 3530
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.7431977391242981,
      "learning_rate": 1.690253671562083e-05,
      "loss": 0.5152,
      "step": 3540
    },
    {
      "epoch": 2.84,
      "grad_norm": 0.8371216654777527,
      "learning_rate": 1.610146862483311e-05,
      "loss": 0.5435,
      "step": 3550
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.7571089863777161,
      "learning_rate": 1.5300400534045393e-05,
      "loss": 0.5553,
      "step": 3560
    },
    {
      "epoch": 2.856,
      "grad_norm": 0.712365984916687,
      "learning_rate": 1.4499332443257675e-05,
      "loss": 0.5056,
      "step": 3570
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.7481744885444641,
      "learning_rate": 1.369826435246996e-05,
      "loss": 0.5012,
      "step": 3580
    },
    {
      "epoch": 2.872,
      "grad_norm": 0.8140169978141785,
      "learning_rate": 1.2897196261682242e-05,
      "loss": 0.5342,
      "step": 3590
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.775754451751709,
      "learning_rate": 1.2096128170894524e-05,
      "loss": 0.5477,
      "step": 3600
    },
    {
      "epoch": 2.888,
      "grad_norm": 0.693362295627594,
      "learning_rate": 1.1295060080106808e-05,
      "loss": 0.4941,
      "step": 3610
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.7849423885345459,
      "learning_rate": 1.0493991989319092e-05,
      "loss": 0.4974,
      "step": 3620
    },
    {
      "epoch": 2.904,
      "grad_norm": 0.9503737688064575,
      "learning_rate": 9.692923898531374e-06,
      "loss": 0.5372,
      "step": 3630
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.7870064973831177,
      "learning_rate": 8.891855807743658e-06,
      "loss": 0.5266,
      "step": 3640
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.7146893739700317,
      "learning_rate": 8.09078771695594e-06,
      "loss": 0.5231,
      "step": 3650
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.6564833521842957,
      "learning_rate": 7.289719626168224e-06,
      "loss": 0.5728,
      "step": 3660
    },
    {
      "epoch": 2.936,
      "grad_norm": 0.7684647440910339,
      "learning_rate": 6.488651535380506e-06,
      "loss": 0.5111,
      "step": 3670
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.6587574481964111,
      "learning_rate": 5.687583444592789e-06,
      "loss": 0.535,
      "step": 3680
    },
    {
      "epoch": 2.952,
      "grad_norm": 0.7222061157226562,
      "learning_rate": 4.886515353805073e-06,
      "loss": 0.5459,
      "step": 3690
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.7862197160720825,
      "learning_rate": 4.0854472630173565e-06,
      "loss": 0.5409,
      "step": 3700
    },
    {
      "epoch": 2.968,
      "grad_norm": 0.5708706378936768,
      "learning_rate": 3.284379172229639e-06,
      "loss": 0.4959,
      "step": 3710
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.6849687695503235,
      "learning_rate": 2.4833110814419224e-06,
      "loss": 0.5055,
      "step": 3720
    },
    {
      "epoch": 2.984,
      "grad_norm": 0.7557967305183411,
      "learning_rate": 1.6822429906542053e-06,
      "loss": 0.5381,
      "step": 3730
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.8194512128829956,
      "learning_rate": 8.811748998664886e-07,
      "loss": 0.5279,
      "step": 3740
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6372517943382263,
      "learning_rate": 8.01068090787717e-08,
      "loss": 0.5105,
      "step": 3750
    }
  ],
  "logging_steps": 10,
  "max_steps": 3750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.8411131817374515e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
